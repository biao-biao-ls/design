# è®¾è®¡æ–‡æ¡£

## æ¦‚è¿°

KNZN é¡¹ç›®åŸºç¡€æ¶æ„é‡‡ç”¨ç°ä»£åŒ–çš„å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆï¼ŒåŸºäº Nuxt 4 å…¨æ ˆæ¡†æ¶æ„å»ºï¼Œä½¿ç”¨ PostgreSQL ä½œä¸ºä¸»æ•°æ®åº“ï¼Œé€šè¿‡ Docker Compose åœ¨ Contabo VPS ä¸Šå®ç°å®Œå…¨è‡ªæ‰˜ç®¡éƒ¨ç½²ã€‚è¯¥æ¶æ„ä¸“ä¸ºæµ·å¤–å¸‚åœºè®¾è®¡ï¼Œé‡ç‚¹å…³æ³¨ GDPR åˆè§„ã€é‚®ä»¶æœåŠ¡é›†æˆå’Œè·¨æ¶æ„å…¼å®¹æ€§ã€‚

### æ ¸å¿ƒè®¾è®¡åŸåˆ™

1. **å®¹å™¨åŒ–ä¼˜å…ˆ**ï¼šæ‰€æœ‰æœåŠ¡å‡é€šè¿‡ Docker å®¹å™¨åŒ–ï¼Œç¡®ä¿ç¯å¢ƒä¸€è‡´æ€§
2. **è‡ªæ‰˜ç®¡æ§åˆ¶**ï¼šå®Œå…¨æ‘†è„± Supabase ç­‰ç¬¬ä¸‰æ–¹ä¾èµ–ï¼Œè·å¾—æ•°æ®ä¸»æƒ
3. **æµ·å¤–å¸‚åœºé€‚é…**ï¼šå†…ç½® GDPR åˆè§„ã€é‚®ä»¶æœåŠ¡å’Œå¤šè¯­è¨€æ”¯æŒ
4. **å¼€å‘ä½“éªŒä¼˜åŒ–**ï¼šæœ¬åœ°å¼€å‘ç¯å¢ƒä¸ç”Ÿäº§ç¯å¢ƒä¿æŒä¸€è‡´æ€§
5. **å®‰å…¨æ€§ä¼˜å…ˆ**ï¼šç¯å¢ƒå˜é‡éªŒè¯ã€HTTPS å¼ºåˆ¶ã€å®‰å…¨å¤´é…ç½®

## æ¶æ„è®¾è®¡

### ç³»ç»Ÿæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        å®¢æˆ·ç«¯å±‚ (Client Layer)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Web Browser â”‚ Mobile Browser â”‚ Desktop PWA â”‚ API Clients        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Contabo VPS (å•æœºé›†ç¾¤)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Nginx å®¹å™¨ (å…¥å£)                          â”‚
â”‚ â€¢ SSL è¯ä¹¦ç®¡ç† (Cloudflare è¯ä¹¦)                               â”‚
â”‚ â€¢ HTTP/2 + Gzip å‹ç¼©                                           â”‚
â”‚ â€¢ é™æ€èµ„æºç¼“å­˜                                                  â”‚
â”‚ â€¢ åå‘ä»£ç†åˆ° Nuxt å®¹å™¨                                          â”‚
â”‚ â€¢ å®‰å…¨å¤´é…ç½®                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åº”ç”¨å±‚ (Nuxt 4 + Nitro)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Frontend (Vue 3)        â”‚ Backend (Nitro Server)               â”‚
â”‚ â€¢ å“åº”å¼ UI ç»„ä»¶        â”‚ â€¢ API Routes (/api/*)                â”‚
â”‚ â€¢ çŠ¶æ€ç®¡ç† (Pinia)      â”‚ â€¢ è®¤è¯ç³»ç»Ÿ (Better-Auth)             â”‚
â”‚ â€¢ è·¯ç”±ç®¡ç†              â”‚ â€¢ ä¸šåŠ¡é€»è¾‘å¤„ç†                       â”‚
â”‚ â€¢ å®¢æˆ·ç«¯ç¼“å­˜            â”‚ â€¢ æ•°æ®éªŒè¯å’Œå®‰å…¨                     â”‚
â”‚                         â”‚ â€¢ é‚®ä»¶æœåŠ¡é›†æˆ                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ•°æ®å±‚ (Data Layer)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PostgreSQL å®¹å™¨     â”‚ Redis å®¹å™¨        â”‚ Cloudflare R2         â”‚
â”‚ â€¢ ç”¨æˆ·æ•°æ®          â”‚ â€¢ Nitro ç¼“å­˜      â”‚ â€¢ é™æ€æ–‡ä»¶å­˜å‚¨        â”‚
â”‚ â€¢ åº”ç”¨æ•°æ®          â”‚ â€¢ ä¼šè¯å­˜å‚¨        â”‚ â€¢ å›¾ç‰‡å’Œæ–‡æ¡£          â”‚
â”‚ â€¢ ç³»ç»Ÿé…ç½®          â”‚ â€¢ é™æµæ§åˆ¶        â”‚ â€¢ å¤‡ä»½æ–‡ä»¶            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æŠ€æœ¯æ ˆé€‰å‹

#### å‰ç«¯æŠ€æœ¯æ ˆ
- **æ¡†æ¶**: Nuxt 4 (Vue 3) - å…¨æ ˆæ¡†æ¶ï¼ŒSSR æ”¯æŒï¼ŒSEO å‹å¥½
- **æ ·å¼**: UnoCSS - åŸå­åŒ– CSSï¼ŒæŒ‰éœ€ç”Ÿæˆï¼Œé›¶è¿è¡Œæ—¶å¼€é”€
- **çŠ¶æ€ç®¡ç†**: Pinia - Vue å®˜æ–¹æ¨èï¼ŒTypeScript æ”¯æŒå®Œç¾
- **å·¥å…·åº“**: VueUse - é«˜è´¨é‡ Composition API å·¥å…·é›†
- **å›¾æ ‡**: Iconify - æŒ‰éœ€å¼•å…¥ï¼Œ10ä¸‡+ å›¾æ ‡åº“
- **åŠ¨ç”»**: CSS Transitions + Motion One - è½»é‡çº§åŠ¨ç”»è§£å†³æ–¹æ¡ˆ

#### åç«¯æŠ€æœ¯æ ˆ
- **è¿è¡Œæ—¶**: Nuxt 4 Server (Nitro) - é«˜æ€§èƒ½æœåŠ¡ç«¯æ¸²æŸ“å¼•æ“
- **æ•°æ®åº“**: PostgreSQL 15 - ä¼ä¸šçº§å…³ç³»å‹æ•°æ®åº“
- **ORM**: Drizzle ORM - è½»é‡ã€Type-safeã€å†·å¯åŠ¨å¿«
- **è®¤è¯**: Better-Auth - ç°ä»£åŒ–è®¤è¯è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒ OAuth
- **é‚®ä»¶**: Resend - å¼€å‘è€…å‹å¥½çš„é‚®ä»¶æœåŠ¡
- **å­˜å‚¨**: Cloudflare R2 - æˆæœ¬ä½å»‰çš„å¯¹è±¡å­˜å‚¨

#### éƒ¨ç½²æŠ€æœ¯æ ˆ
- **å®¹å™¨åŒ–**: Docker + Docker Compose - æ ‡å‡†åŒ–å®¹å™¨ç¼–æ’
- **Web æœåŠ¡å™¨**: Nginx - é«˜æ€§èƒ½åå‘ä»£ç†å’Œé™æ€æ–‡ä»¶æœåŠ¡
- **SSL**: Cloudflare SSL è¯ä¹¦ - ä½¿ç”¨ç°æœ‰è¯ä¹¦æ–‡ä»¶
- **VPS**: Contabo VPS L (12GB RAM, 6 CPU cores) - é«˜æ€§ä»·æ¯”æœåŠ¡å™¨
- **CI/CD**: GitHub Actions - è‡ªåŠ¨åŒ–æ„å»ºå’Œéƒ¨ç½²

## ç»„ä»¶å’Œæ¥å£

### æ ¸å¿ƒç»„ä»¶æ¶æ„

#### 1. è®¤è¯æœåŠ¡ç»„ä»¶ (Authentication Service)

```typescript
// server/utils/auth.ts
import { betterAuth } from "better-auth"
import { drizzleAdapter } from "better-auth/adapters/drizzle"
import { db } from "~/server/database/connection"

export const auth = betterAuth({
  database: drizzleAdapter(db, {
    provider: "pg"
  }),
  
  // æµ·å¤–å¸‚åœºæ ‡é…ï¼šEmail + OAuth
  socialProviders: {
    google: {
      clientId: process.env.GOOGLE_CLIENT_ID!,
      clientSecret: process.env.GOOGLE_CLIENT_SECRET!,
    },
    github: {
      clientId: process.env.GITHUB_CLIENT_ID!,
      clientSecret: process.env.GITHUB_CLIENT_SECRET!,
    }
  },
  
  // Magic Link ç™»å½•ï¼ˆæµ·å¤–ç”¨æˆ·åå¥½ï¼‰
  emailAndPassword: {
    enabled: true,
    requireEmailVerification: true
  },
  
  magicLink: {
    enabled: true
  },
  
  session: {
    cookieCache: {
      enabled: true,
      maxAge: 60 * 60 * 24 * 7 // 7 days
    }
  }
})
```

#### 2. æ•°æ®åº“è¿æ¥ç»„ä»¶ (Database Connection)

```typescript
// server/database/connection.ts
import { drizzle } from 'drizzle-orm/postgres-js'
import postgres from 'postgres'

// ç¯å¢ƒå˜é‡éªŒè¯
const requiredEnvVars = [
  'DATABASE_URL',
  'DATABASE_HOST',
  'DATABASE_NAME',
  'DATABASE_USER',
  'DATABASE_PASSWORD'
]

for (const envVar of requiredEnvVars) {
  if (!process.env[envVar]) {
    throw new Error(`Missing required environment variable: ${envVar}`)
  }
}

const connectionConfig = {
  host: process.env.DATABASE_HOST,
  port: 5432,
  database: process.env.DATABASE_NAME,
  user: process.env.DATABASE_USER,
  password: process.env.DATABASE_PASSWORD,
  
  // è¿æ¥æ± è®¾ç½® (12GB RAM å¯æ”¯æŒæ›´å¤šè¿æ¥)
  max: 30,
  min: 5,
  idle: 30000,
  acquire: 60000,
  
  ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false
}

const queryClient = postgres(process.env.DATABASE_URL!, connectionConfig)
export const db = drizzle(queryClient)
```

#### 3. é‚®ä»¶æœåŠ¡ç»„ä»¶ (Email Service)

```typescript
// server/utils/email.ts
interface EmailTemplate {
  subject: string
  template: string
  attachments?: boolean
}

const EMAIL_TEMPLATES: Record<string, EmailTemplate> = {
  welcome: {
    subject: 'Welcome to KNZN - Your Hardware Learning Journey Begins!',
    template: 'welcome-email.html'
  },
  magicLink: {
    subject: 'Sign in to KNZN',
    template: 'magic-link.html'
  },
  passwordReset: {
    subject: 'Reset Your KNZN Password',
    template: 'password-reset.html'
  }
}

export const sendEmail = async (options: {
  to: string
  template: string
  data: Record<string, any>
  attachments?: Buffer[]
}) => {
  // ç¯å¢ƒå˜é‡éªŒè¯
  if (!process.env.RESEND_API_KEY) {
    throw new Error('Missing RESEND_API_KEY environment variable')
  }
  
  const templateConfig = EMAIL_TEMPLATES[options.template]
  if (!templateConfig) {
    throw new Error(`Unknown email template: ${options.template}`)
  }
  
  try {
    const response = await fetch('https://api.resend.com/emails', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.RESEND_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        from: 'KNZN <noreply@knzn.net>',
        to: options.to,
        subject: templateConfig.subject,
        html: await renderTemplate(options.template, options.data),
        attachments: options.attachments
      })
    })
    
    if (!response.ok) {
      throw new Error(`Email sending failed: ${response.statusText}`)
    }
    
    return await response.json()
  } catch (error) {
    console.error('Email sending error:', error)
    throw error
  }
}
```

#### 4. ç¯å¢ƒå˜é‡éªŒè¯ç»„ä»¶ (Environment Validation)

```typescript
// server/utils/env-validation.ts
import { z } from 'zod'

const envSchema = z.object({
  // æ•°æ®åº“é…ç½®
  DATABASE_URL: z.string().url(),
  DATABASE_HOST: z.string().min(1),
  DATABASE_NAME: z.string().min(1),
  DATABASE_USER: z.string().min(1),
  DATABASE_PASSWORD: z.string().min(8),
  
  // OAuth é…ç½®
  GOOGLE_CLIENT_ID: z.string().min(1),
  GOOGLE_CLIENT_SECRET: z.string().min(1),
  GITHUB_CLIENT_ID: z.string().min(1),
  GITHUB_CLIENT_SECRET: z.string().min(1),
  
  // é‚®ä»¶æœåŠ¡
  RESEND_API_KEY: z.string().startsWith('re_'),
  
  // æ–‡ä»¶å­˜å‚¨
  R2_ACCESS_KEY_ID: z.string().min(1),
  R2_SECRET_ACCESS_KEY: z.string().min(1),
  CLOUDFLARE_ACCOUNT_ID: z.string().min(1),
  
  // ç«™ç‚¹é…ç½®
  SITE_URL: z.string().url(),
  
  // Better Auth å¯†é’¥
  BETTER_AUTH_SECRET: z.string().min(32),
  
  // å¤‡ä»½åŠ å¯†
  BACKUP_PASSWORD: z.string().min(16)
})

export function validateEnvironment() {
  try {
    const validatedEnv = envSchema.parse(process.env)
    console.log('âœ… Environment variables validated successfully')
    return validatedEnv
  } catch (error) {
    console.error('âŒ Environment validation failed:')
    if (error instanceof z.ZodError) {
      error.errors.forEach(err => {
        console.error(`  - ${err.path.join('.')}: ${err.message}`)
      })
    }
    process.exit(1)
  }
}

// Nuxt Runtime Config é›†æˆ
// nuxt.config.ts
export default defineNuxtConfig({
  runtimeConfig: {
    // ç§æœ‰é…ç½®ï¼ˆä»…æœåŠ¡ç«¯ï¼‰
    databaseUrl: process.env.DATABASE_URL,
    googleClientId: process.env.GOOGLE_CLIENT_ID,
    googleClientSecret: process.env.GOOGLE_CLIENT_SECRET,
    githubClientId: process.env.GITHUB_CLIENT_ID,
    githubClientSecret: process.env.GITHUB_CLIENT_SECRET,
    resendApiKey: process.env.RESEND_API_KEY,
    r2AccessKeyId: process.env.R2_ACCESS_KEY_ID,
    r2SecretAccessKey: process.env.R2_SECRET_ACCESS_KEY,
    cloudflareAccountId: process.env.CLOUDFLARE_ACCOUNT_ID,
    betterAuthSecret: process.env.BETTER_AUTH_SECRET,
    backupPassword: process.env.BACKUP_PASSWORD,
    
    // å…¬å…±é…ç½®ï¼ˆå®¢æˆ·ç«¯å¯è®¿é—®ï¼‰
    public: {
      siteUrl: process.env.SITE_URL || 'https://knzn.net'
    }
  },
  
  // å¯åŠ¨æ—¶éªŒè¯ç¯å¢ƒå˜é‡
  hooks: {
    'ready': () => {
      validateEnvironment()
    }
  }
})
```

### API æ¥å£è®¾è®¡

#### 1. è®¤è¯ API æ¥å£

```typescript
// server/api/auth/[...all].ts
import { auth } from "~/server/utils/auth"

export default defineEventHandler(async (event) => {
  return auth.handler(toWebRequest(event))
})
```

#### 2. å¥åº·æ£€æŸ¥ API

```typescript
// server/api/health.get.ts
export default defineEventHandler(async (event) => {
  try {
    // æ£€æŸ¥æ•°æ®åº“è¿æ¥
    await db.execute(sql`SELECT 1`)
    
    // æ£€æŸ¥ Redis è¿æ¥ (å¦‚æœä½¿ç”¨)
    // await redis.ping()
    
    return {
      status: 'healthy',
      timestamp: new Date().toISOString(),
      services: {
        database: 'connected',
        // redis: 'connected'
      }
    }
  } catch (error) {
    setResponseStatus(event, 503)
    return {
      status: 'unhealthy',
      timestamp: new Date().toISOString(),
      error: error.message
    }
  }
})
```

#### 3. GDPR åˆè§„ API

```typescript
// server/api/privacy/export-data.post.ts
export default defineEventHandler(async (event) => {
  const session = await getUserSession(event)
  if (!session) {
    throw createError({ statusCode: 401, statusMessage: 'Unauthorized' })
  }
  
  const userId = session.user.id
  
  // æ”¶é›†ç”¨æˆ·æ•°æ®
  const userData = {
    profile: await getUserProfile(userId),
    createdAt: new Date().toISOString(),
    exportedAt: new Date().toISOString()
  }
  
  return {
    data: userData,
    format: 'json',
    gdprCompliant: true
  }
})

// server/api/privacy/delete-account.post.ts
export default defineEventHandler(async (event) => {
  const session = await getUserSession(event)
  if (!session) {
    throw createError({ statusCode: 401, statusMessage: 'Unauthorized' })
  }
  
  const userId = session.user.id
  
  // æ ‡è®°è´¦æˆ·ä¸ºå¾…åˆ é™¤çŠ¶æ€ï¼ˆ30å¤©å®½é™æœŸï¼‰
  await db.update(users)
    .set({ 
      deletionScheduledAt: new Date(Date.now() + 30 * 24 * 60 * 60 * 1000),
      status: 'pending_deletion'
    })
    .where(eq(users.id, userId))
  
  // å‘é€ç¡®è®¤é‚®ä»¶
  await sendEmail({
    to: session.user.email,
    template: 'account-deletion-scheduled',
    data: { userName: session.user.name }
  })
  
  return {
    message: 'Account deletion scheduled',
    gracePeriod: '30 days',
    gdprCompliant: true
  }
})
```

## æ•°æ®æ¨¡å‹

### æ ¸å¿ƒæ•°æ®è¡¨ç»“æ„

```typescript
// server/database/schema.ts
import { pgTable, text, integer, boolean, timestamp, serial, jsonb } from 'drizzle-orm/pg-core'

// ç”¨æˆ·è¡¨
export const users = pgTable('users', {
  id: text('id').primaryKey().$defaultFn(() => generateId()),
  name: text('name').notNull(),
  email: text('email').unique().notNull(),
  avatarUrl: text('avatar_url'),
  emailVerified: boolean('email_verified').default(false),
  createdAt: timestamp('created_at').defaultNow(),
  updatedAt: timestamp('updated_at').defaultNow(),
  lastActiveAt: timestamp('last_active_at').defaultNow(),
  
  // GDPR åˆè§„å­—æ®µ
  gdprConsent: boolean('gdpr_consent').default(false),
  gdprConsentDate: timestamp('gdpr_consent_date'),
  deletionScheduledAt: timestamp('deletion_scheduled_at'),
  status: text('status').default('active') // 'active', 'pending_deletion', 'deleted'
})

// OAuth è´¦å·å…³è”è¡¨
export const accounts = pgTable('accounts', {
  id: text('id').primaryKey(),
  userId: text('user_id').references(() => users.id, { onDelete: 'cascade' }),
  provider: text('provider').notNull(), // 'google', 'github'
  providerAccountId: text('provider_account_id').notNull(),
  accessToken: text('access_token'),
  refreshToken: text('refresh_token'),
  expiresAt: timestamp('expires_at'),
  createdAt: timestamp('created_at').defaultNow()
})

// ä¼šè¯è¡¨
export const sessions = pgTable('sessions', {
  id: text('id').primaryKey(),
  userId: text('user_id').references(() => users.id, { onDelete: 'cascade' }),
  expiresAt: timestamp('expires_at').notNull(),
  ipAddress: text('ip_address'),
  userAgent: text('user_agent'),
  createdAt: timestamp('created_at').defaultNow()
})

// ç³»ç»Ÿé…ç½®è¡¨
export const systemConfigs = pgTable('system_configs', {
  id: serial('id').primaryKey(),
  key: text('key').unique().notNull(),
  value: jsonb('value').notNull(),
  description: text('description'),
  updatedAt: timestamp('updated_at').defaultNow(),
  updatedBy: text('updated_by').references(() => users.id)
})

// é”™è¯¯æ—¥å¿—è¡¨
export const errorLogs = pgTable('error_logs', {
  id: text('id').primaryKey().$defaultFn(() => generateId()),
  level: text('level').notNull(), // 'error', 'warn', 'info'
  message: text('message').notNull(),
  stack: text('stack'),
  userId: text('user_id').references(() => users.id),
  url: text('url'),
  userAgent: text('user_agent'),
  ipAddress: text('ip_address'),
  createdAt: timestamp('created_at').defaultNow()
})

// å¤‡ä»½æ—¥å¿—è¡¨
export const backupLogs = pgTable('backup_logs', {
  id: text('id').primaryKey().$defaultFn(() => generateId()),
  type: text('type').notNull(), // 'manual', 'scheduled', 'restore'
  status: text('status').notNull(), // 'completed', 'failed', 'in_progress'
  fileSize: text('file_size'),
  fileName: text('file_name'),
  error: text('error'),
  createdBy: text('created_by').references(() => users.id),
  createdAt: timestamp('created_at').defaultNow()
})
```

### æ•°æ®åº“è¿ç§»ç­–ç•¥

```typescript
// drizzle.config.ts
import type { Config } from 'drizzle-kit'

export default {
  schema: './server/database/schema.ts',
  out: './drizzle',
  dialect: 'postgresql',
  dbCredentials: {
    url: process.env.DATABASE_URL!
  },
  verbose: true,
  strict: true
} satisfies Config
```

```json
// package.json scripts
{
  "scripts": {
    "db:generate": "drizzle-kit generate",
    "db:migrate": "drizzle-kit migrate",
    "db:migrate:prod": "NODE_ENV=production drizzle-kit migrate",
    "db:studio": "drizzle-kit studio",
    "db:push": "drizzle-kit push",
    "db:reset": "rm -rf ./drizzle && npm run db:generate",
    "validate-env": "node -e \"require('./server/utils/env-validation').validateEnvironment()\"",
    
    // å¼€å‘ç¯å¢ƒè„šæœ¬
    "dev": "nuxt dev",
    "dev:docker": "docker-compose -f docker-compose.dev.yml up -d && npm run dev",
    "dev:stop": "docker-compose -f docker-compose.dev.yml down",
    "db:migrate:dev": "DATABASE_URL=postgresql://knzn_user:password@localhost:5432/knzn_development drizzle-kit migrate"
  }
}
```

```typescript
// server/utils/migration-runner.ts
import { migrate } from 'drizzle-orm/postgres-js/migrator'
import { db } from './connection'

export async function runMigrations() {
  try {
    console.log('ğŸ”„ Running database migrations...')
    
    await migrate(db, { 
      migrationsFolder: './drizzle',
      migrationsTable: 'drizzle_migrations'
    })
    
    console.log('âœ… Database migrations completed successfully')
  } catch (error) {
    console.error('âŒ Database migration failed:', error)
    
    // è®°å½•è¿ç§»å¤±è´¥åˆ°æ•°æ®åº“ï¼ˆå¦‚æœå¯èƒ½ï¼‰
    try {
      await logMigrationError(error)
    } catch (logError) {
      console.error('Failed to log migration error:', logError)
    }
    
    throw error
  }
}

// åœ¨åº”ç”¨å¯åŠ¨æ—¶è‡ªåŠ¨è¿è¡Œè¿ç§»
// server/plugins/migration.ts
export default defineNitroPlugin(async (nitroApp) => {
  if (process.env.NODE_ENV === 'production') {
    try {
      await runMigrations()
    } catch (error) {
      console.error('Migration failed during startup:', error)
      process.exit(1)
    }
  }
})
```

## å®¹å™¨åŒ–é…ç½®

### Docker Compose é…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Nginx åå‘ä»£ç†
  nginx:
    build: ./docker/nginx
    container_name: knzn-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro  # æŒ‚è½½ Cloudflare è¯ä¹¦
    depends_on:
      - app
    restart: unless-stopped
    networks:
      - knzn-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Nuxt 4 åº”ç”¨
  app:
    build:
      context: .
      dockerfile: ./docker/app/Dockerfile
      platforms:
        - linux/amd64  # ç¡®ä¿ AMD64 æ¶æ„å…¼å®¹æ€§
    container_name: knzn-app
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://knzn_user:${DATABASE_PASSWORD}@postgres:5432/knzn_production
    env_file:
      - .env.production
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - knzn-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # PostgreSQL æ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    container_name: knzn-postgres
    environment:
      POSTGRES_DB: knzn_production
      POSTGRES_USER: knzn_user
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped
    networks:
      - knzn-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U knzn_user -d knzn_production"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:

networks:
  knzn-network:
    driver: bridge
```

### Nuxt åº”ç”¨ Dockerfile

```dockerfile
# docker/app/Dockerfile
FROM node:18-alpine AS base

# å®‰è£…ä¾èµ–é˜¶æ®µ
FROM base AS deps
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

# æ„å»ºé˜¶æ®µ
FROM base AS builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .

# ç¯å¢ƒå˜é‡éªŒè¯
RUN npm run validate-env

# ç”Ÿæˆæ•°æ®åº“è¿ç§»æ–‡ä»¶
RUN npm run db:generate

# æ„å»ºåº”ç”¨
RUN npm run build

# ç”Ÿäº§è¿è¡Œé˜¶æ®µ
FROM base AS runner
WORKDIR /app

# åˆ›å»ºé root ç”¨æˆ·
RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nuxtjs

# å¤åˆ¶æ„å»ºäº§ç‰©å’Œè¿ç§»æ–‡ä»¶
COPY --from=builder --chown=nuxtjs:nodejs /app/.output /app/.output
COPY --from=builder --chown=nuxtjs:nodejs /app/drizzle /app/drizzle
COPY --from=deps --chown=nuxtjs:nodejs /app/node_modules /app/node_modules

# å¤åˆ¶è¿ç§»è„šæœ¬
COPY --from=builder --chown=nuxtjs:nodejs /app/package.json /app/package.json

USER nuxtjs

EXPOSE 3000

ENV PORT 3000
ENV HOST 0.0.0.0

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/api/health || exit 1

# å¯åŠ¨è„šæœ¬ï¼šå…ˆè¿è¡Œè¿ç§»ï¼Œå†å¯åŠ¨åº”ç”¨
CMD ["sh", "-c", "npm run db:migrate:prod && node .output/server/index.mjs"]
```

### å¼€å‘ç¯å¢ƒé…ç½®

```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  # ä»…å¯åŠ¨æ•°æ®åº“ï¼ŒNuxt åœ¨æœ¬åœ°è¿è¡Œ
  postgres:
    image: postgres:15-alpine
    container_name: knzn-postgres-dev
    environment:
      POSTGRES_DB: knzn_development
      POSTGRES_USER: knzn_user
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD:-password}
    ports:
      - "5432:5432"
    volumes:
      - postgres_dev_data:/var/lib/postgresql/data
      - ./docker/postgres/init-dev.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U knzn_user -d knzn_development"]
      interval: 10s
      timeout: 5s
      retries: 5

  # PgAdmin (å¯é€‰ï¼Œç”¨äºæ•°æ®åº“ç®¡ç†)
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: knzn-pgadmin-dev
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@knzn.net
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin123}
    ports:
      - "5050:80"
    depends_on:
      - postgres
    restart: unless-stopped

  # Redis (å¼€å‘ç¯å¢ƒç¼“å­˜)
  redis:
    image: redis:7-alpine
    container_name: knzn-redis-dev
    ports:
      - "6379:6379"
    restart: unless-stopped

volumes:
  postgres_dev_data:
```

```bash
# scripts/dev-setup.sh - å¼€å‘ç¯å¢ƒä¸€é”®å¯åŠ¨è„šæœ¬
#!/bin/bash

echo "ğŸš€ Starting KNZN development environment..."

# 1. æ£€æŸ¥ Docker æ˜¯å¦è¿è¡Œ
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Docker is not running. Please start Docker Desktop."
    exit 1
fi

# 2. å¯åŠ¨å¼€å‘æ•°æ®åº“
echo "ğŸ“¦ Starting development database..."
docker-compose -f docker-compose.dev.yml up -d postgres redis

# 3. ç­‰å¾…æ•°æ®åº“å¯åŠ¨
echo "â³ Waiting for database to be ready..."
until docker exec knzn-postgres-dev pg_isready -U knzn_user -d knzn_development; do
  sleep 2
done

# 4. è¿è¡Œæ•°æ®åº“è¿ç§»
echo "ğŸ”„ Running database migrations..."
npm run db:migrate:dev

# 5. å¯åŠ¨ Nuxt å¼€å‘æœåŠ¡å™¨
echo "ğŸŒŸ Starting Nuxt development server..."
npm run dev

echo "âœ… Development environment is ready!"
echo "ğŸ“Š PgAdmin: http://localhost:5050 (admin@knzn.net / admin123)"
echo "ğŸ—„ï¸ Database: postgresql://knzn_user:password@localhost:5432/knzn_development"
```

```json
// package.json å¼€å‘è„šæœ¬æ›´æ–°
{
  "scripts": {
    "dev": "nuxt dev",
    "dev:setup": "bash scripts/dev-setup.sh",
    "dev:docker": "docker-compose -f docker-compose.dev.yml up -d && npm run db:migrate:dev && npm run dev",
    "dev:stop": "docker-compose -f docker-compose.dev.yml down",
    "dev:clean": "docker-compose -f docker-compose.dev.yml down -v && docker system prune -f",
    "validate-env": "node -e \"require('./server/utils/env-validation').validateEnvironment()\"",
    "db:migrate:dev": "DATABASE_URL=postgresql://knzn_user:password@localhost:5432/knzn_development drizzle-kit migrate"
  }
}
```

## éƒ¨ç½²å’Œ CI/CD

### GitHub Actions å·¥ä½œæµ

```yaml
# .github/workflows/deploy.yml
name: Deploy to Contabo VPS

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Validate environment variables
        run: npm run validate-env
        env:
          DATABASE_URL: postgresql://test:test@localhost:5432/test
          DATABASE_HOST: localhost
          DATABASE_NAME: test
          DATABASE_USER: test
          DATABASE_PASSWORD: test
          GOOGLE_CLIENT_ID: test
          GOOGLE_CLIENT_SECRET: test
          GITHUB_CLIENT_ID: test
          GITHUB_CLIENT_SECRET: test
          RESEND_API_KEY: re_test
          R2_ACCESS_KEY_ID: test
          R2_SECRET_ACCESS_KEY: test
          CLOUDFLARE_ACCOUNT_ID: test
          SITE_URL: https://test.com
          BETTER_AUTH_SECRET: test-secret-key-32-characters-long
          BACKUP_PASSWORD: test-backup-password
      
      - name: Run tests
        run: npm run test

  build-and-deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Login to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
      
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/app/Dockerfile
          platforms: linux/amd64  # ç¡®ä¿ AMD64 æ¶æ„
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Deploy to Contabo VPS
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.VPS_HOST }}
          username: ${{ secrets.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          script: |
            cd /opt/knzn
            
            # æ‹‰å–æœ€æ–°é•œåƒ
            docker-compose pull
            
            # æ‰§è¡Œæ•°æ®åº“è¿ç§»
            docker-compose run --rm app npm run db:migrate:prod
            
            # é‡å¯æœåŠ¡
            docker-compose up -d --force-recreate
            
            # æ¸…ç†æ—§é•œåƒ
            docker system prune -f
            
            # å¥åº·æ£€æŸ¥
            sleep 30
            curl -f http://localhost/api/health || exit 1
            
            # éªŒè¯æ•°æ®åº“è¿ç§»æˆåŠŸ
            docker-compose exec -T postgres psql -U knzn_user -d knzn_production -c "SELECT version FROM drizzle_migrations ORDER BY version DESC LIMIT 1;"
```

### è‡ªåŠ¨åŒ–å¤‡ä»½è„šæœ¬

```bash
#!/bin/bash
# scripts/backup.sh - è‡ªåŠ¨å¤‡ä»½è„šæœ¬

set -e

# é…ç½®å˜é‡
BACKUP_DIR="/opt/knzn-backups"
DATE=$(date +%Y%m%d_%H%M%S)
DB_CONTAINER="knzn-postgres"
BACKUP_FILE="knzn_backup_${DATE}.sql"
ENCRYPTED_FILE="${BACKUP_FILE}.gz.enc"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

echo "ğŸ”„ Starting database backup..."

# 1. æ‰§è¡Œæ•°æ®åº“å¤‡ä»½
docker exec $DB_CONTAINER pg_dump -U knzn_user knzn_production > $BACKUP_DIR/$BACKUP_FILE

# æ£€æŸ¥å¤‡ä»½æ˜¯å¦æˆåŠŸ
if [ $? -eq 0 ]; then
    echo "âœ… Database backup completed: $BACKUP_FILE"
else
    echo "âŒ Database backup failed!"
    exit 1
fi

# 2. å‹ç¼©å¤‡ä»½æ–‡ä»¶
echo "ğŸ—œï¸ Compressing backup..."
gzip $BACKUP_DIR/$BACKUP_FILE

# 3. åŠ å¯†å‹ç¼©æ–‡ä»¶
echo "ğŸ” Encrypting backup..."
openssl enc -aes-256-cbc -salt \
    -in $BACKUP_DIR/${BACKUP_FILE}.gz \
    -out $BACKUP_DIR/$ENCRYPTED_FILE \
    -k $BACKUP_PASSWORD

# 4. ä¸Šä¼ åˆ° Cloudflare R2
echo "â˜ï¸ Uploading to R2..."
aws s3 cp $BACKUP_DIR/$ENCRYPTED_FILE \
    s3://knzn-backups/database/$ENCRYPTED_FILE \
    --endpoint-url https://$CLOUDFLARE_ACCOUNT_ID.r2.cloudflarestorage.com

# 5. éªŒè¯å¤‡ä»½å®Œæ•´æ€§
echo "ğŸ” Verifying backup integrity..."
aws s3 ls s3://knzn-backups/database/$ENCRYPTED_FILE \
    --endpoint-url https://$CLOUDFLARE_ACCOUNT_ID.r2.cloudflarestorage.com

if [ $? -eq 0 ]; then
    echo "âœ… Backup verification successful"
else
    echo "âŒ Backup verification failed!"
    exit 1
fi

# 6. æ¸…ç†æœ¬åœ°æ–‡ä»¶
rm $BACKUP_DIR/${BACKUP_FILE}.gz
rm $BACKUP_DIR/$ENCRYPTED_FILE

# 7. æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™30å¤©ï¼‰
echo "ğŸ§¹ Cleaning old backups..."
aws s3 ls s3://knzn-backups/database/ \
    --endpoint-url https://$CLOUDFLARE_ACCOUNT_ID.r2.cloudflarestorage.com \
    | awk '$1 < "'$(date -d '30 days ago' '+%Y-%m-%d')'" {print $4}' \
    | xargs -I {} aws s3 rm s3://knzn-backups/database/{} \
    --endpoint-url https://$CLOUDFLARE_ACCOUNT_ID.r2.cloudflarestorage.com

echo "ğŸ‰ Backup completed successfully: $ENCRYPTED_FILE"

# 8. è®°å½•å¤‡ä»½æ—¥å¿—åˆ°æ•°æ®åº“
docker exec $DB_CONTAINER psql -U knzn_user -d knzn_production -c "
INSERT INTO backup_logs (id, type, status, file_name, file_size, created_at) 
VALUES (
  '$(uuidgen)', 
  'scheduled', 
  'completed', 
  '$ENCRYPTED_FILE',
  '$(stat -f%z $BACKUP_DIR/$ENCRYPTED_FILE 2>/dev/null || stat -c%s $BACKUP_DIR/$ENCRYPTED_FILE)',
  NOW()
);"
```

### Cron Job é…ç½®

```bash
# åœ¨ VPS ä¸Šé…ç½®å®šæ—¶ä»»åŠ¡
# crontab -e

# æ¯å¤©å‡Œæ™¨ 2 ç‚¹æ‰§è¡Œå¤‡ä»½
0 2 * * * /opt/knzn/scripts/backup.sh >> /var/log/knzn-backup.log 2>&1

# æ¯å‘¨æ—¥å‡Œæ™¨ 3 ç‚¹æ¸…ç† Docker ç³»ç»Ÿ
0 3 * * 0 docker system prune -f >> /var/log/docker-cleanup.log 2>&1

# æ¯æœˆ 1 å·æ£€æŸ¥ SSL è¯ä¹¦æœ‰æ•ˆæœŸï¼ˆCloudflare è¯ä¹¦ï¼‰
0 4 1 * * /opt/knzn/scripts/check-ssl-expiry.sh >> /var/log/ssl-check.log 2>&1
```

ç°åœ¨è®©æˆ‘ç»§ç»­å®Œæˆè®¾è®¡æ–‡æ¡£çš„å‰©ä½™éƒ¨åˆ†...

## æ­£ç¡®æ€§å±æ€§

*å±æ€§æ˜¯ä¸€ä¸ªç‰¹å¾æˆ–è¡Œä¸ºï¼Œåº”è¯¥åœ¨ç³»ç»Ÿçš„æ‰€æœ‰æœ‰æ•ˆæ‰§è¡Œä¸­ä¿æŒä¸ºçœŸâ€”â€”æœ¬è´¨ä¸Šæ˜¯å…³äºç³»ç»Ÿåº”è¯¥åšä»€ä¹ˆçš„æ­£å¼å£°æ˜ã€‚å±æ€§ä½œä¸ºäººç±»å¯è¯»è§„èŒƒå’Œæœºå™¨å¯éªŒè¯æ­£ç¡®æ€§ä¿è¯ä¹‹é—´çš„æ¡¥æ¢ã€‚*

åŸºäºéœ€æ±‚åˆ†æï¼Œä»¥ä¸‹æ˜¯é¡¹ç›®åŸºç¡€æ¶æ„çš„æ ¸å¿ƒæ­£ç¡®æ€§å±æ€§ï¼š

### å±æ€§ 1: ç¯å¢ƒå˜é‡éªŒè¯å®Œæ•´æ€§
*å¯¹äºä»»ä½•* ç¼ºå¤±çš„å…³é”®ç¯å¢ƒå˜é‡ï¼Œç³»ç»Ÿå¯åŠ¨æ—¶åº”è¯¥ç«‹å³å¤±è´¥å¹¶æ˜¾ç¤ºå…·ä½“çš„ç¼ºå¤±å˜é‡åç§°ï¼Œè€Œä¸æ˜¯åœ¨è¿è¡Œæ—¶å´©æºƒ
**éªŒè¯éœ€æ±‚: éœ€æ±‚ 1.7**

### å±æ€§ 2: æ•°æ®åº“è¿ç§»å¹‚ç­‰æ€§
*å¯¹äºä»»ä½•* æ•°æ®åº“è¿ç§»è„šæœ¬ï¼Œå¤šæ¬¡æ‰§è¡Œåº”è¯¥äº§ç”Ÿç›¸åŒçš„æœ€ç»ˆæ•°æ®åº“çŠ¶æ€ï¼Œä¸ä¼šå› é‡å¤æ‰§è¡Œè€Œå‡ºé”™
**éªŒè¯éœ€æ±‚: éœ€æ±‚ 2.2**

### å±æ€§ 3: æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ä¿è¯
*å¯¹äºä»»ä½•* æ ‡å‡†æ•°æ®åº“æŸ¥è¯¢æ“ä½œï¼Œå“åº”æ—¶é—´åº”è¯¥åœ¨ 500 æ¯«ç§’ä»¥å†…ï¼Œç¡®ä¿ç³»ç»Ÿå“åº”æ€§èƒ½
**éªŒè¯éœ€æ±‚: éœ€æ±‚ 2.3**

### å±æ€§ 4: æ•°æ®å¤‡ä»½å®Œæ•´æ€§
*å¯¹äºä»»ä½•* ç”Ÿæˆçš„æ•°æ®åº“å¤‡ä»½æ–‡ä»¶ï¼Œåº”è¯¥åŒ…å«æ‰€æœ‰ç”¨æˆ·æ•°æ®å¹¶ä¸”å¯ä»¥æˆåŠŸæ¢å¤åˆ°æ–°çš„æ•°æ®åº“å®ä¾‹
**éªŒè¯éœ€æ±‚: éœ€æ±‚ 2.5**

### å±æ€§ 5: å®¹å™¨å¯åŠ¨æ€§èƒ½
*å¯¹äºä»»ä½•* å®¹å™¨æœåŠ¡å¯åŠ¨ï¼Œåº”è¯¥åœ¨ 30 ç§’å†…å®Œæˆå¯åŠ¨å¹¶é€šè¿‡å¥åº·æ£€æŸ¥ï¼Œç¡®ä¿å¿«é€Ÿéƒ¨ç½²
**éªŒè¯éœ€æ±‚: éœ€æ±‚ 3.2**

### å±æ€§ 6: å®¹å™¨æ•°æ®æŒä¹…åŒ–
*å¯¹äºä»»ä½•* å®¹å™¨é‡å¯æ“ä½œï¼Œæ‰€æœ‰æŒä¹…åŒ–æ•°æ®åº”è¯¥ä¿æŒå®Œæ•´ï¼ŒæœåŠ¡çŠ¶æ€åº”è¯¥æ­£ç¡®æ¢å¤
**éªŒè¯éœ€æ±‚: éœ€æ±‚ 3.3**

### å±æ€§ 7: æ—¥å¿—è½®è½¬æœºåˆ¶
*å¯¹äºä»»ä½•* è¶…è¿‡ 10MB çš„ Docker æ—¥å¿—æ–‡ä»¶ï¼Œç³»ç»Ÿåº”è¯¥è‡ªåŠ¨æ‰§è¡Œè½®è½¬å¹¶ä¿ç•™æœ€è¿‘ 3 ä»½æ—¥å¿—æ–‡ä»¶
**éªŒè¯éœ€æ±‚: éœ€æ±‚ 3.6**

### å±æ€§ 8: HTTPS é‡å®šå‘ä¸€è‡´æ€§
*å¯¹äºä»»ä½•* HTTP è¯·æ±‚åˆ°å¹³å°åŸŸåï¼ŒæœåŠ¡å™¨åº”è¯¥è‡ªåŠ¨é‡å®šå‘åˆ°å¯¹åº”çš„ HTTPS URL
**éªŒè¯éœ€æ±‚: éœ€æ±‚ 5.1**

### å±æ€§ 9: SSL è¯ä¹¦æœ‰æ•ˆæ€§
*å¯¹äºä»»ä½•* HTTPS è¿æ¥è¯·æ±‚ï¼ŒSSL è¯ä¹¦åº”è¯¥æ˜¯æœ‰æ•ˆçš„ã€æœªè¿‡æœŸçš„ï¼Œå¹¶ä¸”ä¸åŸŸååŒ¹é…
**éªŒè¯éœ€æ±‚: éœ€æ±‚ 5.2**

### å±æ€§ 10: ç›‘æ§æ•°æ®è¿ç»­æ€§
*å¯¹äºä»»ä½•* ç³»ç»Ÿè¿è¡ŒæœŸé—´ï¼Œæ€§èƒ½æŒ‡æ ‡å’Œæ—¥å¿—æ•°æ®åº”è¯¥æŒç»­æ”¶é›†ï¼Œä¸åº”å‡ºç°æ•°æ®ä¸¢å¤±
**éªŒè¯éœ€æ±‚: éœ€æ±‚ 6.1**

### å±æ€§ 11: GDPR æ•°æ®å¯¼å‡ºå®Œæ•´æ€§
*å¯¹äºä»»ä½•* ç”¨æˆ·æ•°æ®å¯¼å‡ºè¯·æ±‚ï¼Œå¯¼å‡ºæ–‡ä»¶åº”è¯¥åŒ…å«è¯¥ç”¨æˆ·çš„æ‰€æœ‰ä¸ªäººæ•°æ®ï¼Œæ ¼å¼åº”è¯¥æ˜¯æœºå™¨å¯è¯»çš„
**éªŒè¯éœ€æ±‚: éœ€æ±‚ 7.2**

### å±æ€§ 12: GDPR æ•°æ®åˆ é™¤å½»åº•æ€§
*å¯¹äºä»»ä½•* è´¦æˆ·åˆ é™¤è¯·æ±‚ï¼Œåœ¨å®½é™æœŸç»“æŸåï¼Œè¯¥ç”¨æˆ·çš„æ‰€æœ‰ä¸ªäººæ•°æ®åº”è¯¥ä»ç³»ç»Ÿä¸­å®Œå…¨æ¸…é™¤
**éªŒè¯éœ€æ±‚: éœ€æ±‚ 7.3**

## é”™è¯¯å¤„ç†

### é”™è¯¯åˆ†ç±»å’Œå¤„ç†ç­–ç•¥

#### 1. ç³»ç»Ÿçº§é”™è¯¯å¤„ç†

```typescript
// server/middleware/error-handler.ts
export default defineEventHandler(async (event) => {
  try {
    // æ­£å¸¸è¯·æ±‚å¤„ç†
    await $fetch(event.node.req.url!)
  } catch (error) {
    // é”™è¯¯åˆ†ç±»å¤„ç†
    if (error instanceof DatabaseConnectionError) {
      // æ•°æ®åº“è¿æ¥é”™è¯¯ - å°è¯•é‡è¿
      await retryDatabaseConnection()
      setResponseStatus(event, 503)
      return { error: 'Database temporarily unavailable', retryAfter: 30 }
    }
    
    if (error instanceof ValidationError) {
      // æ•°æ®éªŒè¯é”™è¯¯ - è¿”å›è¯¦ç»†é”™è¯¯ä¿¡æ¯
      setResponseStatus(event, 400)
      return { error: 'Validation failed', details: error.details }
    }
    
    if (error instanceof AuthenticationError) {
      // è®¤è¯é”™è¯¯ - æ¸…é™¤ä¼šè¯å¹¶é‡å®šå‘
      await clearUserSession(event)
      setResponseStatus(event, 401)
      return { error: 'Authentication required' }
    }
    
    // æœªçŸ¥é”™è¯¯ - è®°å½•æ—¥å¿—å¹¶è¿”å›é€šç”¨é”™è¯¯
    console.error('Unhandled error:', error)
    await logError(error, event)
    setResponseStatus(event, 500)
    return { error: 'Internal server error' }
  }
})
```

#### 2. æ•°æ®åº“é”™è¯¯å¤„ç†

```typescript
// server/utils/database-error-handler.ts
export class DatabaseErrorHandler {
  static async handleConnectionError(error: Error, retryCount = 0): Promise<void> {
    const maxRetries = 3
    const retryDelay = Math.pow(2, retryCount) * 1000 // æŒ‡æ•°é€€é¿
    
    if (retryCount >= maxRetries) {
      // è®°å½•ä¸¥é‡é”™è¯¯å¹¶å‘é€å‘Šè­¦
      await logCriticalError('Database connection failed after max retries', error)
      await sendAlertEmail('Database Connection Critical', error.message)
      throw new Error('Database connection permanently failed')
    }
    
    console.warn(`Database connection failed, retrying in ${retryDelay}ms (attempt ${retryCount + 1}/${maxRetries})`)
    await new Promise(resolve => setTimeout(resolve, retryDelay))
    
    try {
      await testDatabaseConnection()
    } catch (retryError) {
      return this.handleConnectionError(retryError, retryCount + 1)
    }
  }
  
  static async handleMigrationError(error: Error): Promise<void> {
    // è¿ç§»é”™è¯¯å¤„ç† - è®°å½•è¯¦ç»†ä¿¡æ¯ä½†ä¸è‡ªåŠ¨é‡è¯•
    await logError('Database migration failed', error, {
      level: 'critical',
      category: 'database_migration',
      requiresManualIntervention: true
    })
    
    // å‘é€ç´§æ€¥é€šçŸ¥
    await sendAlertEmail('Database Migration Failed', `
      Migration failed with error: ${error.message}
      
      Manual intervention required. Please check the database state and migration scripts.
      
      Stack trace: ${error.stack}
    `)
    
    throw error // ä¸è¦ç»§ç»­æ‰§è¡Œï¼Œéœ€è¦äººå·¥å¹²é¢„
  }
}
```

#### 3. å®¹å™¨é”™è¯¯å¤„ç†

```typescript
// server/utils/container-health.ts
export class ContainerHealthMonitor {
  static async checkContainerHealth(): Promise<HealthStatus> {
    const healthChecks = [
      this.checkDatabaseConnection(),
      this.checkFileSystemAccess(),
      this.checkMemoryUsage(),
      this.checkDiskSpace()
    ]
    
    const results = await Promise.allSettled(healthChecks)
    const failures = results.filter(result => result.status === 'rejected')
    
    if (failures.length > 0) {
      const errors = failures.map(f => f.reason?.message).join(', ')
      await logError('Container health check failed', new Error(errors))
      
      // å¦‚æœæ˜¯å…³é”®æœåŠ¡å¤±è´¥ï¼Œè§¦å‘å®¹å™¨é‡å¯
      if (failures.some(f => f.reason instanceof DatabaseConnectionError)) {
        await this.requestContainerRestart('Database connection failed')
      }
      
      return {
        status: 'unhealthy',
        errors: errors,
        timestamp: new Date().toISOString()
      }
    }
    
    return {
      status: 'healthy',
      timestamp: new Date().toISOString()
    }
  }
  
  static async requestContainerRestart(reason: string): Promise<void> {
    console.error(`Requesting container restart: ${reason}`)
    
    // è®°å½•é‡å¯è¯·æ±‚
    await logError('Container restart requested', new Error(reason), {
      level: 'warning',
      category: 'container_management'
    })
    
    // åœ¨ Docker ç¯å¢ƒä¸­ï¼Œå¥åº·æ£€æŸ¥å¤±è´¥ä¼šè‡ªåŠ¨è§¦å‘é‡å¯
    // è¿™é‡Œæˆ‘ä»¬åªéœ€è¦ç¡®ä¿è¿›ç¨‹é€€å‡º
    process.exit(1)
  }
}
```

#### 4. GDPR åˆè§„é”™è¯¯å¤„ç†

```typescript
// server/utils/gdpr-error-handler.ts
export class GDPRComplianceHandler {
  static async handleDataExportError(userId: string, error: Error): Promise<void> {
    // æ•°æ®å¯¼å‡ºå¤±è´¥ - è®°å½•å¹¶é€šçŸ¥ç”¨æˆ·
    await logError('GDPR data export failed', error, {
      userId,
      level: 'high',
      category: 'gdpr_compliance',
      requiresUserNotification: true
    })
    
    // å‘é€ç”¨æˆ·é€šçŸ¥é‚®ä»¶
    const user = await getUserById(userId)
    if (user) {
      await sendEmail({
        to: user.email,
        template: 'data-export-failed',
        data: {
          userName: user.name,
          supportEmail: 'privacy@knzn.net',
          errorReference: generateErrorReference()
        }
      })
    }
  }
  
  static async handleDataDeletionError(userId: string, error: Error): Promise<void> {
    // æ•°æ®åˆ é™¤å¤±è´¥ - è¿™æ˜¯ä¸¥é‡çš„åˆè§„é—®é¢˜
    await logCriticalError('GDPR data deletion failed', error, {
      userId,
      category: 'gdpr_compliance',
      requiresImmediateAction: true
    })
    
    // å‘é€ç´§æ€¥é€šçŸ¥ç»™ç®¡ç†å‘˜
    await sendAlertEmail('CRITICAL: GDPR Data Deletion Failed', `
      User ${userId} data deletion failed.
      
      This is a critical GDPR compliance issue that requires immediate attention.
      
      Error: ${error.message}
      Stack: ${error.stack}
      
      Please manually verify and complete the data deletion process.
    `)
    
    // æ ‡è®°ç”¨æˆ·ä¸ºéœ€è¦æ‰‹åŠ¨å¤„ç†
    await markUserForManualDeletion(userId, error.message)
  }
}
```

### é”™è¯¯ç›‘æ§å’Œå‘Šè­¦

```typescript
// server/utils/error-monitoring.ts
export class ErrorMonitoring {
  static async logError(
    message: string, 
    error: Error, 
    context: {
      level?: 'info' | 'warning' | 'high' | 'critical'
      category?: string
      userId?: string
      url?: string
      userAgent?: string
      ipAddress?: string
      requiresUserNotification?: boolean
      requiresImmediateAction?: boolean
    } = {}
  ): Promise<void> {
    const errorLog = {
      id: generateId(),
      level: context.level || 'high',
      message,
      stack: error.stack,
      userId: context.userId,
      url: context.url,
      userAgent: context.userAgent,
      ipAddress: context.ipAddress,
      category: context.category,
      createdAt: new Date()
    }
    
    // è®°å½•åˆ°æ•°æ®åº“
    await db.insert(errorLogs).values(errorLog)
    
    // æ ¹æ®é”™è¯¯çº§åˆ«å†³å®šé€šçŸ¥æ–¹å¼
    if (context.level === 'critical' || context.requiresImmediateAction) {
      await this.sendCriticalAlert(errorLog)
    } else if (context.level === 'high') {
      await this.sendHighPriorityAlert(errorLog)
    }
    
    // å¦‚æœéœ€è¦é€šçŸ¥ç”¨æˆ·
    if (context.requiresUserNotification && context.userId) {
      await this.notifyUser(context.userId, errorLog)
    }
    
    // é›†æˆç¬¬ä¸‰æ–¹é”™è¯¯è¿½è¸ªæœåŠ¡
    await this.sendToErrorTracking(errorLog, error)
  }
  
  static async sendCriticalAlert(errorLog: ErrorLog): Promise<void> {
    // å‘é€é‚®ä»¶å‘Šè­¦
    await sendEmail({
      to: 'alerts@knzn.net',
      template: 'critical-error-alert',
      data: {
        errorId: errorLog.id,
        message: errorLog.message,
        category: errorLog.category,
        timestamp: errorLog.createdAt.toISOString(),
        level: errorLog.level
      }
    })
  }
  
  static async sendToErrorTracking(errorLog: ErrorLog, error: Error): Promise<void> {
    // é›†æˆ Sentry æˆ– GlitchTip
    if (process.env.SENTRY_DSN) {
      try {
        // è¿™é‡Œå¯ä»¥é›†æˆ Sentry SDK
        console.log('Sending error to Sentry:', errorLog.id)
      } catch (sentryError) {
        console.error('Failed to send error to Sentry:', sentryError)
      }
    }
    
    // æˆ–è€…ä½¿ç”¨è½»é‡çº§çš„ GlitchTip
    if (process.env.GLITCHTIP_DSN) {
      try {
        await fetch(process.env.GLITCHTIP_DSN, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            message: errorLog.message,
            level: errorLog.level,
            timestamp: errorLog.createdAt.toISOString(),
            extra: {
              category: errorLog.category,
              userId: errorLog.userId,
              url: errorLog.url
            },
            exception: {
              values: [{
                type: error.constructor.name,
                value: error.message,
                stacktrace: { frames: parseStackTrace(error.stack) }
              }]
            }
          })
        })
      } catch (glitchTipError) {
        console.error('Failed to send error to GlitchTip:', glitchTipError)
      }
    }
  }
}

// server/middleware/error-logger.ts
export default defineEventHandler(async (event) => {
  // æ•è·æœªå¤„ç†çš„é”™è¯¯
  process.on('unhandledRejection', async (reason, promise) => {
    await ErrorMonitoring.logError(
      'Unhandled Promise Rejection',
      reason instanceof Error ? reason : new Error(String(reason)),
      { level: 'critical', category: 'unhandled_rejection' }
    )
  })
  
  process.on('uncaughtException', async (error) => {
    await ErrorMonitoring.logError(
      'Uncaught Exception',
      error,
      { level: 'critical', category: 'uncaught_exception' }
    )
    
    // ç»™é”™è¯¯å¤„ç†ä¸€äº›æ—¶é—´ï¼Œç„¶åé€€å‡º
    setTimeout(() => process.exit(1), 1000)
  })
})
```

### Docker æ—¥å¿—é…ç½®

```yaml
# docker-compose.yml æ—¥å¿—é…ç½®æ›´æ–°
version: '3.8'

services:
  nginx:
    # ... å…¶ä»–é…ç½®
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        compress: "true"

  app:
    # ... å…¶ä»–é…ç½®
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        compress: "true"
        labels: "service=knzn-app"

  postgres:
    # ... å…¶ä»–é…ç½®
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        compress: "true"
        labels: "service=knzn-postgres"
```

### ç³»ç»Ÿç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# scripts/monitor-system.sh - ç³»ç»Ÿç›‘æ§è„šæœ¬

# æ£€æŸ¥å®¹å™¨çŠ¶æ€
check_containers() {
    echo "ğŸ” Checking container health..."
    
    containers=("knzn-nginx" "knzn-app" "knzn-postgres")
    
    for container in "${containers[@]}"; do
        if ! docker ps --filter "name=$container" --filter "status=running" | grep -q $container; then
            echo "âŒ Container $container is not running"
            
            # å‘é€å‘Šè­¦
            curl -X POST "https://api.resend.com/emails" \
                -H "Authorization: Bearer $RESEND_API_KEY" \
                -H "Content-Type: application/json" \
                -d "{
                    \"from\": \"alerts@knzn.net\",
                    \"to\": \"admin@knzn.net\",
                    \"subject\": \"Container Alert: $container Down\",
                    \"html\": \"Container $container is not running. Please check the system immediately.\"
                }"
        else
            echo "âœ… Container $container is healthy"
        fi
    done
}

# æ£€æŸ¥ç£ç›˜ç©ºé—´
check_disk_space() {
    echo "ğŸ’¾ Checking disk space..."
    
    disk_usage=$(df / | awk 'NR==2 {print $5}' | sed 's/%//')
    
    if [ $disk_usage -gt 80 ]; then
        echo "âš ï¸ Disk usage is ${disk_usage}%"
        
        # æ¸…ç† Docker ç³»ç»Ÿ
        docker system prune -f
        
        # å¦‚æœä»ç„¶è¶…è¿‡ 85%ï¼Œå‘é€å‘Šè­¦
        disk_usage_after=$(df / | awk 'NR==2 {print $5}' | sed 's/%//')
        if [ $disk_usage_after -gt 85 ]; then
            curl -X POST "https://api.resend.com/emails" \
                -H "Authorization: Bearer $RESEND_API_KEY" \
                -H "Content-Type: application/json" \
                -d "{
                    \"from\": \"alerts@knzn.net\",
                    \"to\": \"admin@knzn.net\",
                    \"subject\": \"Disk Space Alert: ${disk_usage_after}% Used\",
                    \"html\": \"Disk usage is critically high at ${disk_usage_after}%. Please free up space immediately.\"
                }"
        fi
    else
        echo "âœ… Disk usage is ${disk_usage}% (healthy)"
    fi
}

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
check_memory() {
    echo "ğŸ§  Checking memory usage..."
    
    memory_usage=$(free | awk 'NR==2{printf "%.0f", $3*100/$2}')
    
    if [ $memory_usage -gt 85 ]; then
        echo "âš ï¸ Memory usage is ${memory_usage}%"
        
        # å‘é€å‘Šè­¦
        curl -X POST "https://api.resend.com/emails" \
            -H "Authorization: Bearer $RESEND_API_KEY" \
            -H "Content-Type: application/json" \
            -d "{
                \"from\": \"alerts@knzn.net\",
                \"to\": \"admin@knzn.net\",
                \"subject\": \"Memory Alert: ${memory_usage}% Used\",
                \"html\": \"Memory usage is high at ${memory_usage}%. System may need attention.\"
            }"
    else
        echo "âœ… Memory usage is ${memory_usage}% (healthy)"
    fi
}

# æ£€æŸ¥åº”ç”¨å¥åº·çŠ¶æ€
check_app_health() {
    echo "ğŸ¥ Checking application health..."
    
    health_response=$(curl -s -o /dev/null -w "%{http_code}" http://localhost/api/health)
    
    if [ $health_response -ne 200 ]; then
        echo "âŒ Application health check failed (HTTP $health_response)"
        
        # å°è¯•é‡å¯åº”ç”¨å®¹å™¨
        docker-compose restart app
        
        # ç­‰å¾…é‡å¯
        sleep 30
        
        # å†æ¬¡æ£€æŸ¥
        health_response_retry=$(curl -s -o /dev/null -w "%{http_code}" http://localhost/api/health)
        
        if [ $health_response_retry -ne 200 ]; then
            # å‘é€ç´§æ€¥å‘Šè­¦
            curl -X POST "https://api.resend.com/emails" \
                -H "Authorization: Bearer $RESEND_API_KEY" \
                -H "Content-Type: application/json" \
                -d "{
                    \"from\": \"alerts@knzn.net\",
                    \"to\": \"admin@knzn.net\",
                    \"subject\": \"CRITICAL: Application Down\",
                    \"html\": \"Application health check failed even after restart. Manual intervention required.\"
                }"
        fi
    else
        echo "âœ… Application is healthy"
    fi
}

# æ‰§è¡Œæ‰€æœ‰æ£€æŸ¥
main() {
    echo "ğŸš€ Starting system monitoring..."
    echo "Timestamp: $(date)"
    
    check_containers
    check_disk_space
    check_memory
    check_app_health
    
    echo "âœ… System monitoring completed"
}

main
```

### SSL è¯ä¹¦æ£€æŸ¥è„šæœ¬

```bash
#!/bin/bash
# scripts/check-ssl-expiry.sh - SSL è¯ä¹¦æœ‰æ•ˆæœŸæ£€æŸ¥è„šæœ¬

echo "ğŸ” Checking SSL certificate expiry..."

CERT_FILE="/opt/knzn/ssl/cf_cert.pem"
DOMAIN="knzn.net"

# æ£€æŸ¥è¯ä¹¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if [ ! -f "$CERT_FILE" ]; then
    echo "âŒ Certificate file not found: $CERT_FILE"
    
    # å‘é€å‘Šè­¦é‚®ä»¶
    curl -X POST "https://api.resend.com/emails" \
        -H "Authorization: Bearer $RESEND_API_KEY" \
        -H "Content-Type: application/json" \
        -d "{
            \"from\": \"alerts@knzn.net\",
            \"to\": \"admin@knzn.net\",
            \"subject\": \"SSL Certificate File Missing\",
            \"html\": \"SSL certificate file $CERT_FILE is missing. Please check the certificate configuration.\"
        }"
    exit 1
fi

# æ£€æŸ¥è¯ä¹¦æœ‰æ•ˆæœŸ
EXPIRY_DATE=$(openssl x509 -in "$CERT_FILE" -noout -enddate | cut -d= -f2)
EXPIRY_TIMESTAMP=$(date -d "$EXPIRY_DATE" +%s)
CURRENT_TIMESTAMP=$(date +%s)
DAYS_UNTIL_EXPIRY=$(( (EXPIRY_TIMESTAMP - CURRENT_TIMESTAMP) / 86400 ))

echo "ğŸ“… Certificate expires on: $EXPIRY_DATE"
echo "â° Days until expiry: $DAYS_UNTIL_EXPIRY"

# å¦‚æœè¯ä¹¦åœ¨ 30 å¤©å†…è¿‡æœŸï¼Œå‘é€æé†’
if [ $DAYS_UNTIL_EXPIRY -lt 30 ]; then
    echo "âš ï¸ Certificate expires in $DAYS_UNTIL_EXPIRY days"
    
    # å‘é€æé†’é‚®ä»¶
    curl -X POST "https://api.resend.com/emails" \
        -H "Authorization: Bearer $RESEND_API_KEY" \
        -H "Content-Type: application/json" \
        -d "{
            \"from\": \"alerts@knzn.net\",
            \"to\": \"admin@knzn.net\",
            \"subject\": \"SSL Certificate Expiry Warning\",
            \"html\": \"SSL certificate for $DOMAIN will expire in $DAYS_UNTIL_EXPIRY days on $EXPIRY_DATE. Please renew the certificate from Cloudflare.\"
        }"
elif [ $DAYS_UNTIL_EXPIRY -lt 0 ]; then
    echo "âŒ Certificate has expired!"
    
    # å‘é€ç´§æ€¥å‘Šè­¦
    curl -X POST "https://api.resend.com/emails" \
        -H "Authorization: Bearer $RESEND_API_KEY" \
        -H "Content-Type: application/json" \
        -d "{
            \"from\": \"alerts@knzn.net\",
            \"to\": \"admin@knzn.net\",
            \"subject\": \"CRITICAL: SSL Certificate Expired\",
            \"html\": \"SSL certificate for $DOMAIN has expired on $EXPIRY_DATE. Immediate action required to renew the certificate.\"
        }"
else
    echo "âœ… Certificate is valid for $DAYS_UNTIL_EXPIRY more days"
fi

# éªŒè¯è¯ä¹¦ä¸åŸŸååŒ¹é…
CERT_DOMAIN=$(openssl x509 -in "$CERT_FILE" -noout -subject | grep -o 'CN=[^,]*' | cut -d= -f2)
if [ "$CERT_DOMAIN" != "$DOMAIN" ] && [ "$CERT_DOMAIN" != "*.$DOMAIN" ]; then
    echo "âš ï¸ Certificate domain mismatch: expected $DOMAIN, got $CERT_DOMAIN"
fi

echo "ğŸ” SSL certificate check completed"
```

### Cron Job é…ç½®æ›´æ–°

```bash
# åœ¨ VPS ä¸Šé…ç½®å®šæ—¶ä»»åŠ¡
# crontab -e

# æ¯å¤©å‡Œæ™¨ 2 ç‚¹æ‰§è¡Œå¤‡ä»½
0 2 * * * /opt/knzn/scripts/backup.sh >> /var/log/knzn-backup.log 2>&1

# æ¯ 5 åˆ†é’Ÿæ£€æŸ¥ç³»ç»ŸçŠ¶æ€
*/5 * * * * /opt/knzn/scripts/monitor-system.sh >> /var/log/knzn-monitor.log 2>&1

# æ¯å‘¨æ—¥å‡Œæ™¨ 3 ç‚¹æ¸…ç† Docker ç³»ç»Ÿ
0 3 * * 0 docker system prune -f >> /var/log/docker-cleanup.log 2>&1

# æ¯æœˆ 1 å·æ£€æŸ¥ SSL è¯ä¹¦æœ‰æ•ˆæœŸï¼ˆCloudflare è¯ä¹¦ï¼‰
0 4 1 * * /opt/knzn/scripts/check-ssl-expiry.sh >> /var/log/ssl-check.log 2>&1

# æ¯å¤©å‡Œæ™¨ 1 ç‚¹è½®è½¬åº”ç”¨æ—¥å¿—
0 1 * * * /usr/sbin/logrotate /etc/logrotate.d/knzn-app
```
```

## æµ‹è¯•ç­–ç•¥

### åŒé‡æµ‹è¯•æ–¹æ³•

æˆ‘ä»¬é‡‡ç”¨**å•å…ƒæµ‹è¯•**å’Œ**åŸºäºå±æ€§çš„æµ‹è¯•**ç›¸ç»“åˆçš„ç»¼åˆæµ‹è¯•ç­–ç•¥ï¼š

- **å•å…ƒæµ‹è¯•**ï¼šéªŒè¯å…·ä½“ç¤ºä¾‹ã€è¾¹ç•Œæƒ…å†µå’Œé”™è¯¯æ¡ä»¶
- **åŸºäºå±æ€§çš„æµ‹è¯•**ï¼šéªŒè¯æ‰€æœ‰è¾“å…¥èŒƒå›´å†…çš„é€šç”¨å±æ€§
- **é›†æˆæµ‹è¯•**ï¼šéªŒè¯ç»„ä»¶é—´äº¤äº’å’Œç«¯åˆ°ç«¯æµç¨‹

### åŸºäºå±æ€§çš„æµ‹è¯•é…ç½®

æˆ‘ä»¬ä½¿ç”¨ **fast-check** ä½œä¸º JavaScript/TypeScript çš„å±æ€§æµ‹è¯•åº“ï¼š

```typescript
// tests/properties/infrastructure.test.ts
import fc from 'fast-check'
import { describe, test, expect } from 'vitest'

describe('Infrastructure Properties', () => {
  test('Property 1: Environment variable validation completeness', () => {
    fc.assert(fc.property(
      fc.array(fc.string(), { minLength: 1 }), // éšæœºç¯å¢ƒå˜é‡åæ•°ç»„
      (missingVars) => {
        // å¯¹äºä»»ä½•ç¼ºå¤±çš„ç¯å¢ƒå˜é‡ï¼Œç³»ç»Ÿåº”è¯¥ç«‹å³å¤±è´¥
        const originalEnv = { ...process.env }
        
        // åˆ é™¤æŒ‡å®šçš„ç¯å¢ƒå˜é‡
        missingVars.forEach(varName => {
          delete process.env[varName]
        })
        
        try {
          const result = validateEnvironment()
          // å¦‚æœæ²¡æœ‰æŠ›å‡ºé”™è¯¯ï¼Œè¯´æ˜è¿™äº›å˜é‡ä¸æ˜¯å¿…éœ€çš„
          expect(result).toBeDefined()
        } catch (error) {
          // å¦‚æœæŠ›å‡ºé”™è¯¯ï¼Œåº”è¯¥åŒ…å«ç¼ºå¤±å˜é‡çš„ä¿¡æ¯
          missingVars.forEach(varName => {
            if (REQUIRED_ENV_VARS.includes(varName)) {
              expect(error.message).toContain(varName)
            }
          })
        } finally {
          // æ¢å¤ç¯å¢ƒå˜é‡
          process.env = originalEnv
        }
      }
    ), { numRuns: 100 })
  })
  
  test('Property 2: Database migration idempotency', () => {
    fc.assert(fc.property(
      fc.integer({ min: 1, max: 5 }), // æ‰§è¡Œæ¬¡æ•°
      async (executionCount) => {
        // å¯¹äºä»»ä½•è¿ç§»è„šæœ¬ï¼Œå¤šæ¬¡æ‰§è¡Œåº”è¯¥äº§ç”Ÿç›¸åŒç»“æœ
        const initialState = await getDatabaseSchema()
        
        // æ‰§è¡Œè¿ç§»å¤šæ¬¡
        for (let i = 0; i < executionCount; i++) {
          await runMigrations()
        }
        
        const finalState = await getDatabaseSchema()
        
        // æœ€ç»ˆçŠ¶æ€åº”è¯¥ä¸å•æ¬¡æ‰§è¡Œçš„ç»“æœç›¸åŒ
        await resetDatabase()
        await runMigrations()
        const singleExecutionState = await getDatabaseSchema()
        
        expect(finalState).toEqual(singleExecutionState)
      }
    ), { numRuns: 50 })
  })
  
  test('Property 3: Database query performance guarantee', () => {
    fc.assert(fc.property(
      fc.record({
        table: fc.constantFrom('users', 'sessions', 'system_configs'),
        limit: fc.integer({ min: 1, max: 100 }),
        offset: fc.integer({ min: 0, max: 1000 })
      }),
      async (queryParams) => {
        // å¯¹äºä»»ä½•æ ‡å‡†æŸ¥è¯¢ï¼Œå“åº”æ—¶é—´åº”è¯¥åœ¨ 500ms å†…
        const startTime = Date.now()
        
        await db.select()
          .from(queryParams.table)
          .limit(queryParams.limit)
          .offset(queryParams.offset)
        
        const duration = Date.now() - startTime
        expect(duration).toBeLessThan(500)
      }
    ), { numRuns: 100 })
  })
  
  test('Property 7: Log rotation mechanism', () => {
    fc.assert(fc.property(
      fc.integer({ min: 11, max: 50 }), // æ—¥å¿—æ–‡ä»¶å¤§å° (MB)
      async (logSizeMB) => {
        // å¯¹äºä»»ä½•è¶…è¿‡ 10MB çš„æ—¥å¿—ï¼Œåº”è¯¥è§¦å‘è½®è½¬
        const logContent = 'x'.repeat(logSizeMB * 1024 * 1024)
        
        // æ¨¡æ‹Ÿå†™å…¥å¤§é‡æ—¥å¿—
        await writeLogFile('test.log', logContent)
        
        // è§¦å‘æ—¥å¿—è½®è½¬æ£€æŸ¥
        await checkLogRotation()
        
        // éªŒè¯è½®è½¬ç»“æœ
        const logFiles = await getLogFiles()
        const activeLogSize = await getFileSize('test.log')
        
        // ä¸»æ—¥å¿—æ–‡ä»¶åº”è¯¥è¢«è½®è½¬ï¼Œå¤§å°åº”è¯¥å°äº 10MB
        expect(activeLogSize).toBeLessThan(10 * 1024 * 1024)
        
        // åº”è¯¥ä¿ç•™æœ€è¿‘ 3 ä»½è½®è½¬æ—¥å¿—
        const rotatedLogs = logFiles.filter(f => f.includes('.log.'))
        expect(rotatedLogs.length).toBeLessThanOrEqual(3)
      }
    ), { numRuns: 20 })
  })
})
```

### å•å…ƒæµ‹è¯•ç¤ºä¾‹

```typescript
// tests/unit/auth.test.ts
import { describe, test, expect, beforeEach } from 'vitest'
import { auth } from '~/server/utils/auth'

describe('Authentication System', () => {
  beforeEach(async () => {
    await resetTestDatabase()
  })
  
  test('should create user session on successful login', async () => {
    const user = await createTestUser({
      email: 'test@example.com',
      password: 'password123'
    })
    
    const session = await auth.signIn.email({
      email: 'test@example.com',
      password: 'password123'
    })
    
    expect(session.user.id).toBe(user.id)
    expect(session.session.expiresAt).toBeInstanceOf(Date)
  })
  
  test('should handle OAuth provider errors gracefully', async () => {
    // æ¨¡æ‹Ÿ OAuth æä¾›å•†é”™è¯¯
    mockOAuthProvider('google', { error: 'invalid_grant' })
    
    await expect(
      auth.signIn.social({ provider: 'google' })
    ).rejects.toThrow('OAuth authentication failed')
  })
  
  test('should enforce GDPR data export within 30 days', async () => {
    const user = await createTestUser()
    const exportRequest = await requestDataExport(user.id)
    
    // éªŒè¯å¯¼å‡ºè¯·æ±‚è¢«æ­£ç¡®è®°å½•
    expect(exportRequest.status).toBe('pending')
    expect(exportRequest.requestedAt).toBeInstanceOf(Date)
    
    // æ¨¡æ‹Ÿ 30 å¤©åçš„å¤„ç†
    const exportData = await processDataExport(user.id)
    
    expect(exportData).toHaveProperty('profile')
    expect(exportData).toHaveProperty('createdAt')
    expect(exportData.gdprCompliant).toBe(true)
  })
})
```

### é›†æˆæµ‹è¯•

```typescript
// tests/integration/deployment.test.ts
import { describe, test, expect } from 'vitest'

describe('Deployment Integration', () => {
  test('should complete full deployment cycle', async () => {
    // 1. æ„å»º Docker é•œåƒ
    const buildResult = await buildDockerImage()
    expect(buildResult.success).toBe(true)
    expect(buildResult.imageId).toBeDefined()
    
    // 2. å¯åŠ¨å®¹å™¨
    const containerResult = await startContainer(buildResult.imageId)
    expect(containerResult.containerId).toBeDefined()
    
    // 3. ç­‰å¾…å¥åº·æ£€æŸ¥é€šè¿‡
    await waitForHealthCheck(containerResult.containerId, 30000)
    
    // 4. éªŒè¯æœåŠ¡å¯ç”¨æ€§
    const healthResponse = await fetch('http://localhost:3000/api/health')
    expect(healthResponse.status).toBe(200)
    
    const healthData = await healthResponse.json()
    expect(healthData.status).toBe('healthy')
    
    // 5. æ¸…ç†
    await stopContainer(containerResult.containerId)
  })
  
  test('should handle database migration in deployment', async () => {
    // éƒ¨ç½²å‰çš„æ•°æ®åº“çŠ¶æ€
    const initialSchema = await getDatabaseSchema()
    
    // æ‰§è¡Œéƒ¨ç½²ï¼ˆåŒ…å«è¿ç§»ï¼‰
    await deployWithMigration()
    
    // éªŒè¯è¿ç§»æ‰§è¡ŒæˆåŠŸ
    const finalSchema = await getDatabaseSchema()
    expect(finalSchema.version).toBeGreaterThan(initialSchema.version)
    
    // éªŒè¯æ•°æ®å®Œæ•´æ€§
    const userData = await db.select().from(users).limit(1)
    expect(userData).toBeDefined()
  })
})
```

### æµ‹è¯•é…ç½®

```typescript
// vitest.config.ts
import { defineConfig } from 'vitest/config'

export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    setupFiles: ['./tests/setup.ts'],
    testTimeout: 30000, // 30 ç§’è¶…æ—¶ï¼Œé€‚åˆé›†æˆæµ‹è¯•
    
    // åŸºäºå±æ€§çš„æµ‹è¯•é…ç½®
    pool: 'threads',
    poolOptions: {
      threads: {
        minThreads: 1,
        maxThreads: 4
      }
    }
  }
})
```

æ¯ä¸ªå±æ€§æµ‹è¯•è¿è¡Œæœ€å°‘ 100 æ¬¡è¿­ä»£ï¼Œç¡®ä¿å……åˆ†çš„éšæœºè¾“å…¥è¦†ç›–ã€‚æµ‹è¯•æ ‡ç­¾æ ¼å¼ï¼š**Feature: project-infrastructure, Property {number}: {property_text}**ï¼Œä¾¿äºè¿½è¸ªå’Œç»´æŠ¤ã€‚

## æŠ€æœ¯é£é™©å’Œç¼“è§£ç­–ç•¥

### Nuxt 4 å…¼å®¹æ€§é£é™©

**é£é™©æè¿°**: Nuxt 4 ç›®å‰ï¼ˆæˆªè‡³ 2024 å¹´åº•ï¼‰å¯èƒ½éƒ¨åˆ†æ¨¡å—å°šæœªå®Œå…¨é€‚é…ï¼ŒæŸäº›å…³é”® Nuxt Modulesï¼ˆå¦‚ nuxt-security æˆ–æŸäº› UI åº“ï¼‰å¯èƒ½æŠ¥é”™ã€‚

**ç¼“è§£ç­–ç•¥**:
1. **é™çº§é¢„æ¡ˆ**: å¦‚æœå‘ç°å…³é”®æ¨¡å—ä¸å…¼å®¹ï¼Œå‡†å¤‡é™çº§åˆ° Nuxt 3 çš„é¢„æ¡ˆ
2. **æ¸è¿›å¼å‡çº§**: Nuxt 3 åˆ° 4 çš„è¿ç§»é€šå¸¸å¾ˆå¹³æ»‘ï¼Œå¯ä»¥å…ˆç”¨ Nuxt 3 å¯åŠ¨é¡¹ç›®
3. **æ¨¡å—æ›¿ä»£**: ä¸ºå…³é”®åŠŸèƒ½å‡†å¤‡æ›¿ä»£æ–¹æ¡ˆï¼Œé¿å…ä¾èµ–å•ä¸€æ¨¡å—

```typescript
// nuxt.config.ts - å…¼å®¹æ€§é…ç½®
export default defineNuxtConfig({
  // å¦‚æœ Nuxt 4 å‡ºç°é—®é¢˜ï¼Œå¯ä»¥å¿«é€Ÿåˆ‡æ¢åˆ° Nuxt 3
  future: {
    compatibilityVersion: process.env.NUXT_COMPATIBILITY_VERSION === '3' ? 3 : 4
  },
  
  // æ¨¡å—å…¼å®¹æ€§æ£€æŸ¥
  modules: [
    // ä¼˜å…ˆä½¿ç”¨ç¨³å®šçš„æ ¸å¿ƒæ¨¡å—
    '@nuxtjs/tailwindcss',
    '@pinia/nuxt',
    '@vueuse/nuxt',
    
    // å¯é€‰æ¨¡å—ï¼Œå¦‚æœä¸å…¼å®¹å¯ä»¥ç§»é™¤
    // '@nuxtjs/google-fonts', // å¯ä»¥ç”¨ CDN æ›¿ä»£
    // 'nuxt-security', // å¯ä»¥ç”¨ä¸­é—´ä»¶æ›¿ä»£
  ],
  
  // å…¼å®¹æ€§æ£€æŸ¥é’©å­
  hooks: {
    'modules:before': () => {
      console.log('Checking Nuxt module compatibility...')
    },
    'modules:done': () => {
      console.log('All modules loaded successfully')
    }
  }
})
```

### è·¨æ¶æ„æ„å»ºé£é™©

**é£é™©æè¿°**: åœ¨ Apple Silicon Mac ä¸Šæ„å»ºçš„é•œåƒå¯èƒ½æ— æ³•åœ¨ AMD64 VPS ä¸Šè¿è¡Œã€‚

**ç¼“è§£ç­–ç•¥**:
1. **CI/CD æ„å»º**: ä¼˜å…ˆä½¿ç”¨ GitHub Actions åœ¨ AMD64 ç¯å¢ƒä¸­æ„å»º
2. **æœ¬åœ°è·¨æ¶æ„æ„å»º**: ä½¿ç”¨ `docker buildx` è¿›è¡Œè·¨æ¶æ„æ„å»º
3. **æ¶æ„æ£€æµ‹**: åœ¨éƒ¨ç½²è„šæœ¬ä¸­æ·»åŠ æ¶æ„å…¼å®¹æ€§æ£€æŸ¥

```bash
# scripts/check-architecture.sh
#!/bin/bash

echo "ğŸ” Checking Docker image architecture compatibility..."

IMAGE_NAME="ghcr.io/your-username/knzn-app:latest"

# æ£€æŸ¥é•œåƒæ¶æ„
ARCH=$(docker inspect $IMAGE_NAME --format='{{.Architecture}}')

if [ "$ARCH" != "amd64" ]; then
    echo "âŒ Image architecture is $ARCH, but VPS requires amd64"
    echo "Please rebuild with: docker buildx build --platform linux/amd64"
    exit 1
else
    echo "âœ… Image architecture is compatible (amd64)"
fi
```

### æ•°æ®åº“è¿ç§»é£é™©

**é£é™©æè¿°**: ç”Ÿäº§ç¯å¢ƒæ•°æ®åº“è¿ç§»å¤±è´¥å¯èƒ½å¯¼è‡´æœåŠ¡ä¸å¯ç”¨ã€‚

**ç¼“è§£ç­–ç•¥**:
1. **è¿ç§»å‰å¤‡ä»½**: æ¯æ¬¡è¿ç§»å‰è‡ªåŠ¨åˆ›å»ºæ•°æ®åº“å¤‡ä»½
2. **è¿ç§»éªŒè¯**: åœ¨æµ‹è¯•ç¯å¢ƒä¸­éªŒè¯è¿ç§»è„šæœ¬
3. **å›æ»šæœºåˆ¶**: å‡†å¤‡å¿«é€Ÿå›æ»šåˆ°ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬çš„æœºåˆ¶

```typescript
// server/utils/safe-migration.ts
export async function safeMigration() {
  try {
    // 1. åˆ›å»ºè¿ç§»å‰å¤‡ä»½
    console.log('Creating pre-migration backup...')
    await createBackup('pre-migration')
    
    // 2. æ‰§è¡Œè¿ç§»
    console.log('Running migrations...')
    await runMigrations()
    
    // 3. éªŒè¯è¿ç§»ç»“æœ
    console.log('Validating migration...')
    await validateMigration()
    
    console.log('âœ… Migration completed successfully')
  } catch (error) {
    console.error('âŒ Migration failed:', error)
    
    // 4. è‡ªåŠ¨å›æ»š
    console.log('Attempting automatic rollback...')
    await rollbackMigration()
    
    throw error
  }
}
```