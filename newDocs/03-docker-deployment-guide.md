# Docker å®¹å™¨åŒ–éƒ¨ç½²æŠ€æœ¯æŒ‡å¯¼æ–‡æ¡£

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

**é€‚ç”¨åœºæ™¯**: éœ€è¦å®¹å™¨åŒ–éƒ¨ç½²çš„å…¨æ ˆé¡¹ç›®  
**æŠ€æœ¯ç‰¹ç‚¹**: Docker + Docker Compose + ä¸€é”®éƒ¨ç½²  
**å‚è€ƒé¡¹ç›®**: ç¡¬ä»¶å­¦ä¹ å¹³å°çš„ Docker éƒ¨ç½²æ–¹æ¡ˆ  
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  

## ğŸ¯ æ¶æ„æ¦‚è¿°

åŸºäºå½“å‰é¡¹ç›®éªŒè¯çš„ Docker å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆï¼Œæä¾›ï¼š

- **ç¯å¢ƒä¸€è‡´æ€§**: å¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ç¯å¢ƒå®Œå…¨ä¸€è‡´
- **å¿«é€Ÿéƒ¨ç½²**: ä¸€é”®éƒ¨ç½²è„šæœ¬ï¼Œ5åˆ†é’Ÿå®Œæˆéƒ¨ç½²
- **æ˜“äºç»´æŠ¤**: å®¹å™¨åŒ–ç®¡ç†ï¼ŒæœåŠ¡éš”ç¦»
- **å¯æ‰©å±•æ€§**: æ”¯æŒæ°´å¹³æ‰©å±•å’Œè´Ÿè½½å‡è¡¡

## ğŸ—ï¸ éƒ¨ç½²æ¶æ„

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        å¤–éƒ¨è®¿é—®å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ HTTPS (443) â”‚ HTTP (80) â”‚ åŸŸåè§£æ â”‚ SSL è¯ä¹¦                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Nginx åå‘ä»£ç†å®¹å™¨                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ è·¯ç”±åˆ†å‘ (hw.knzn.net â†’ web, admin.knzn.net â†’ admin)        â”‚
â”‚ â€¢ SSL ç»ˆç«¯                                                      â”‚
â”‚ â€¢ è´Ÿè½½å‡è¡¡                                                      â”‚
â”‚ â€¢ é™æ€èµ„æºç¼“å­˜                                                  â”‚
â”‚ â€¢ Gzip å‹ç¼©                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web å‰ç«¯å®¹å™¨    â”‚ â”‚ Admin åå°å®¹å™¨   â”‚ â”‚  Backend APIå®¹å™¨ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Nuxt 4 SSR     â”‚ â”‚ â€¢ Nuxt 4 SSR     â”‚ â”‚ â€¢ NestJS         â”‚
â”‚ â€¢ Vue 3          â”‚ â”‚ â€¢ Element Plus   â”‚ â”‚ â€¢ Fastify        â”‚
â”‚ â€¢ ç«¯å£: 3000     â”‚ â”‚ â€¢ ç«¯å£: 3001     â”‚ â”‚ â€¢ ç«¯å£: 4000     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL å®¹å™¨  â”‚ â”‚   Redis å®¹å™¨     â”‚ â”‚  Qdrant å®¹å™¨     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ ä¸»æ•°æ®åº“       â”‚ â”‚ â€¢ ç¼“å­˜           â”‚ â”‚ â€¢ å‘é‡æ•°æ®åº“     â”‚
â”‚ â€¢ ç«¯å£: 5432     â”‚ â”‚ â€¢ ä¼šè¯å­˜å‚¨       â”‚ â”‚ â€¢ ç«¯å£: 6333     â”‚
â”‚ â€¢ æ•°æ®æŒä¹…åŒ–     â”‚ â”‚ â€¢ ç«¯å£: 6379     â”‚ â”‚ â€¢ æ•°æ®æŒä¹…åŒ–     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Docker é…ç½®æ–‡ä»¶ç»“æ„

```
project-root/
â”œâ”€â”€ docker-compose.yml              # å¼€å‘ç¯å¢ƒé…ç½®
â”œâ”€â”€ docker-compose.prod.yml         # ç”Ÿäº§ç¯å¢ƒé…ç½®
â”œâ”€â”€ .env                            # å¼€å‘ç¯å¢ƒå˜é‡
â”œâ”€â”€ .env.production                 # ç”Ÿäº§ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ .env.production.local           # ç”Ÿäº§ç¯å¢ƒå®é™…é…ç½®ï¼ˆä¸æäº¤ï¼‰
â”‚
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/
â”‚   â”‚   â”œâ”€â”€ Dockerfile              # Web å‰ç«¯ Dockerfile
â”‚   â”‚   â””â”€â”€ .dockerignore
â”‚   â”œâ”€â”€ admin/
â”‚   â”‚   â”œâ”€â”€ Dockerfile              # Admin åå° Dockerfile
â”‚   â”‚   â””â”€â”€ .dockerignore
â”‚   â””â”€â”€ backend/
â”‚       â”œâ”€â”€ Dockerfile              # Backend API Dockerfile
â”‚       â””â”€â”€ .dockerignore
â”‚
â”œâ”€â”€ nginx/
â”‚   â”œâ”€â”€ nginx.conf                  # ç”Ÿäº§ç¯å¢ƒ Nginx é…ç½®
â”‚   â””â”€â”€ nginx.local.conf            # æœ¬åœ°é¢„è§ˆ Nginx é…ç½®
â”‚
â”œâ”€â”€ ssl/                            # SSL è¯ä¹¦ç›®å½•
â”‚   â”œâ”€â”€ cf_cert.pem                 # SSL è¯ä¹¦
â”‚   â””â”€â”€ cf_key.pem                  # SSL ç§é’¥
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ deploy-local.sh             # ä¸€é”®éƒ¨ç½²è„šæœ¬
    â”œâ”€â”€ backup.sh                   # æ•°æ®å¤‡ä»½è„šæœ¬
    â””â”€â”€ restore.sh                  # æ•°æ®æ¢å¤è„šæœ¬
```

## ğŸ³ Docker Compose é…ç½®

### 1. å¼€å‘ç¯å¢ƒé…ç½®

```yaml
# docker-compose.yml
services:
  # PostgreSQL æ•°æ®åº“
  postgres:
    image: postgres:17-alpine
    container_name: project-postgres
    restart: unless-stopped
    ports:
      - '${POSTGRES_PORT:-5432}:5432'
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-my_project}
      POSTGRES_INITDB_ARGS: '-E UTF8 --locale=C'
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U ${POSTGRES_USER:-postgres}']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - project-network

  # Redis ç¼“å­˜
  redis:
    image: redis:7.4-alpine
    container_name: project-redis
    restart: unless-stopped
    ports:
      - '${REDIS_PORT:-6379}:6379'
    command:
      - redis-server
      - --appendonly
      - 'yes'
      - --maxmemory
      - 256mb
      - --maxmemory-policy
      - allkeys-lru
    volumes:
      - redis_data:/data
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    networks:
      - project-network
  # å‘é‡æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: project-qdrant
    restart: unless-stopped
    ports:
      - '${QDRANT_PORT:-6333}:6333'
      - '${QDRANT_GRPC_PORT:-6334}:6334'
    environment:
      QDRANT__LOG_LEVEL: ${QDRANT_LOG_LEVEL:-INFO}
    volumes:
      - qdrant_data:/qdrant/storage
    healthcheck:
      test: ['CMD', 'wget', '--no-verbose', '--tries=1', '--spider', 'http://localhost:6333/']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - project-network

  # Nginx åå‘ä»£ç†ï¼ˆæœ¬åœ°é¢„è§ˆæ¨¡å¼ï¼‰
  nginx:
    image: nginx:alpine
    container_name: project-nginx
    profiles:
      - preview
    ports:
      - '80:80'
    volumes:
      - ./nginx/nginx.local.conf:/etc/nginx/nginx.conf:ro
    extra_hosts:
      - 'host.docker.internal:host-gateway'
    networks:
      - project-network

networks:
  project-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  qdrant_data:
    driver: local
```

### 2. ç”Ÿäº§ç¯å¢ƒé…ç½®

```yaml
# docker-compose.prod.yml
services:
  # åç«¯ API æœåŠ¡
  backend:
    build:
      context: .
      dockerfile: apps/backend/Dockerfile
      target: production
      args:
        - NODE_ENV=production
    container_name: project-backend
    restart: unless-stopped
    ports:
      - '4000:4000'
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET=${JWT_SECRET}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - QDRANT_URL=${QDRANT_URL}
      - RUN_SEED=${RUN_SEED:-false}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:4000/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - project-network

  # Web å‰ç«¯æœåŠ¡
  web:
    build:
      context: .
      dockerfile: apps/web/Dockerfile
      target: production
      args:
        - NODE_ENV=production
    container_name: project-web
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - NUXT_PUBLIC_API_BASE=/api
      - BACKEND_INTERNAL_URL=http://backend:4000
    depends_on:
      - backend
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3000']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - project-network

  # ç®¡ç†åå°æœåŠ¡
  admin:
    build:
      context: .
      dockerfile: apps/admin/Dockerfile
      target: production
      args:
        - NODE_ENV=production
    container_name: project-admin
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - NUXT_PUBLIC_API_BASE=/api
      - BACKEND_INTERNAL_URL=http://backend:4000
    depends_on:
      - backend
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3001']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - project-network

  # Nginx åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: project-nginx
    restart: unless-stopped
    ports:
      - '80:80'
      - '443:443'
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - web
      - admin
      - backend
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost/health']
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - project-network

  # PostgreSQL æ•°æ®åº“
  postgres:
    image: postgres:17-alpine
    container_name: project-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_INITDB_ARGS: '-E UTF8 --locale=C'
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U ${POSTGRES_USER}']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - project-network

  # Redis ç¼“å­˜
  redis:
    image: redis:7.4-alpine
    container_name: project-redis
    restart: unless-stopped
    command:
      - redis-server
      - --appendonly
      - 'yes'
      - --requirepass
      - '${REDIS_PASSWORD}'
      - --maxmemory
      - 512mb
      - --maxmemory-policy
      - allkeys-lru
    volumes:
      - redis_data:/data
    healthcheck:
      test: ['CMD', 'redis-cli', '--pass', '${REDIS_PASSWORD}', 'ping']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    networks:
      - project-network

  # å‘é‡æ•°æ®åº“
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: project-qdrant
    restart: unless-stopped
    environment:
      QDRANT__LOG_LEVEL: INFO
      QDRANT__SERVICE__API_KEY: ${QDRANT_API_KEY}
    volumes:
      - qdrant_data:/qdrant/storage
    healthcheck:
      test: ['CMD', 'wget', '--no-verbose', '--tries=1', '--spider', 'http://localhost:6333/']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - project-network

networks:
  project-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  qdrant_data:
    driver: local
```

## ğŸ“¦ Dockerfile é…ç½®

### 1. åç«¯ Dockerfile

```dockerfile
# apps/backend/Dockerfile
# å¤šé˜¶æ®µæ„å»ºï¼Œä¼˜åŒ–é•œåƒå¤§å°
FROM node:20-alpine AS base

# å®‰è£… pnpm
RUN npm install -g pnpm

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ package.json æ–‡ä»¶ï¼ˆåˆ©ç”¨ Docker ç¼“å­˜ï¼‰
COPY package.json pnpm-lock.yaml pnpm-workspace.yaml ./
COPY apps/backend/package.json ./apps/backend/
COPY packages/types/package.json ./packages/types/

# å®‰è£…ä¾èµ–
RUN pnpm install --frozen-lockfile

# å¼€å‘é˜¶æ®µ
FROM base AS development
COPY . .
RUN pnpm --filter @repo/types build
RUN pnpm --filter @repo/backend prisma:generate
RUN pnpm --filter @repo/backend build
EXPOSE 4000
CMD ["pnpm", "--filter", "@repo/backend", "start:prod"]

# ç”Ÿäº§é˜¶æ®µ
FROM base AS production
COPY . .

# æ„å»ºåº”ç”¨
RUN pnpm --filter @repo/types build
RUN pnpm --filter @repo/backend prisma:generate
RUN pnpm --filter @repo/backend build

# æ¸…ç†å¼€å‘ä¾èµ–
RUN pnpm prune --prod

# åˆ›å»ºé root ç”¨æˆ·
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nestjs -u 1001

# è®¾ç½®æƒé™
USER nestjs

EXPOSE 4000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:4000/health || exit 1

CMD ["pnpm", "--filter", "@repo/backend", "start:prod"]
```

### 2. å‰ç«¯ Dockerfile

```dockerfile
# apps/web/Dockerfile
FROM node:20-alpine AS base

RUN npm install -g pnpm

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY package.json pnpm-lock.yaml pnpm-workspace.yaml ./
COPY apps/web/package.json ./apps/web/
COPY packages/types/package.json ./packages/types/
COPY packages/api/package.json ./packages/api/

# å®‰è£…ä¾èµ–
RUN pnpm install --frozen-lockfile

# æ„å»ºé˜¶æ®µ
FROM base AS build
COPY . .

# æ„å»ºå…±äº«åŒ…
RUN pnpm --filter @repo/types build
RUN pnpm --filter @repo/api build

# æ„å»º Web åº”ç”¨
RUN pnpm --filter @repo/web build

# ç”Ÿäº§é˜¶æ®µ
FROM base AS production

# å¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=build /app/.output /app/.output

# åˆ›å»ºé root ç”¨æˆ·
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nuxtjs -u 1001

USER nuxtjs

EXPOSE 3000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000 || exit 1

CMD ["node", ".output/server/index.mjs"]
```

## ğŸŒ Nginx é…ç½®

### 1. ç”Ÿäº§ç¯å¢ƒ Nginx é…ç½®

```nginx
# nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log notice;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # åŸºç¡€é…ç½®
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 50M;

    # Gzip å‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # å®‰å…¨å¤´
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Referrer-Policy "strict-origin-when-cross-origin";

    # ä¸Šæ¸¸æœåŠ¡å™¨å®šä¹‰
    upstream web_backend {
        server web:3000;
        keepalive 32;
    }

    upstream admin_backend {
        server admin:3001;
        keepalive 32;
    }

    upstream api_backend {
        server backend:4000;
        keepalive 32;
    }

    # HTTP é‡å®šå‘åˆ° HTTPS
    server {
        listen 80;
        server_name hw.knzn.net admin.knzn.net;
        return 301 https://$server_name$request_uri;
    }

    # å­¦ç”Ÿç«¯ - hw.knzn.net
    server {
        listen 443 ssl http2;
        server_name hw.knzn.net;

        # SSL é…ç½®
        ssl_certificate /etc/nginx/ssl/cf_cert.pem;
        ssl_certificate_key /etc/nginx/ssl/cf_key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # HSTS
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

        # API è·¯ç”± â†’ Backend
        location /api/ {
            proxy_pass http://api_backend/;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            proxy_read_timeout 300s;
            proxy_connect_timeout 75s;
        }

        # å‰ç«¯è·¯ç”± â†’ Web
        location / {
            proxy_pass http://web_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
        }

        # é™æ€èµ„æºç¼“å­˜
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            proxy_pass http://web_backend;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }

    # ç®¡ç†ç«¯ - admin.knzn.net
    server {
        listen 443 ssl http2;
        server_name admin.knzn.net;

        # SSL é…ç½®ï¼ˆåŒä¸Šï¼‰
        ssl_certificate /etc/nginx/ssl/cf_cert.pem;
        ssl_certificate_key /etc/nginx/ssl/cf_key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

        # API è·¯ç”± â†’ Backend
        location /api/ {
            proxy_pass http://api_backend/;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            proxy_read_timeout 300s;
        }

        # ç®¡ç†ç«¯è·¯ç”± â†’ Admin
        location / {
            proxy_pass http://admin_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
        }
    }

    # å¥åº·æ£€æŸ¥ç«¯ç‚¹
    server {
        listen 80;
        server_name localhost;
        
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
```

## ğŸš€ ä¸€é”®éƒ¨ç½²è„šæœ¬

### æ ¸å¿ƒéƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# scripts/deploy-local.sh

set -e

PROJECT_NAME="my-project"
DEFAULT_BRANCH="main"

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    cat << EOF
Docker å®¹å™¨åŒ–éƒ¨ç½²è„šæœ¬

ç”¨æ³•:
    $0 [é€‰é¡¹]

é€‰é¡¹:
    -h, --help          æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
    -b, --branch BRANCH æŒ‡å®šåˆ†æ”¯ï¼ˆé»˜è®¤: mainï¼‰
    -f, --force         å¼ºåˆ¶éƒ¨ç½²ï¼ˆè·³è¿‡ç¡®è®¤ï¼‰
    --first-deploy      å¼ºåˆ¶é¦–æ¬¡éƒ¨ç½²æ¨¡å¼
    --update-only       å¼ºåˆ¶æ›´æ–°æ¨¡å¼
    --service SERVICE   åªæ›´æ–°æŒ‡å®šæœåŠ¡
    --check             æ£€æŸ¥å½“å‰éƒ¨ç½²çŠ¶æ€
    --logs              æ˜¾ç¤ºæœåŠ¡æ—¥å¿—
    --backup            åˆ›å»ºæ•°æ®å¤‡ä»½

ç¤ºä¾‹:
    $0                  # æ™ºèƒ½éƒ¨ç½²
    $0 -b dev           # éƒ¨ç½² dev åˆ†æ”¯
    $0 --service web    # åªæ›´æ–° web æœåŠ¡
    $0 --backup         # åˆ›å»ºæ•°æ®å¤‡ä»½

EOF
}

# æ£€æŸ¥ç¯å¢ƒ
check_environment() {
    log_info "æ£€æŸ¥éƒ¨ç½²ç¯å¢ƒ..."
    
    # æ£€æŸ¥å¿…éœ€å·¥å…·
    local missing_tools=()
    
    for tool in git docker; do
        if ! command -v "$tool" &> /dev/null; then
            missing_tools+=("$tool")
        fi
    done
    
    if [ ${#missing_tools[@]} -gt 0 ]; then
        log_error "ç¼ºå¤±å¿…éœ€å·¥å…·: ${missing_tools[*]}"
        exit 1
    fi
    
    # æ£€æŸ¥ Docker æœåŠ¡
    if ! docker info &> /dev/null; then
        log_error "Docker æœåŠ¡æœªè¿è¡Œ"
        exit 1
    fi
    
    # æ£€æŸ¥ Docker Compose
    if ! docker compose version &> /dev/null; then
        log_error "Docker Compose æœªå®‰è£…æˆ–ç‰ˆæœ¬è¿‡ä½"
        exit 1
    fi
    
    log_success "ç¯å¢ƒæ£€æŸ¥é€šè¿‡"
}

# æ£€æŸ¥ SSL è¯ä¹¦
check_ssl_certificates() {
    log_info "æ£€æŸ¥ SSL è¯ä¹¦..."
    
    if [ ! -d "./ssl" ]; then
        mkdir -p ./ssl
    fi
    
    local required_files=("cf_cert.pem" "cf_key.pem")
    local missing_files=()
    
    for file in "${required_files[@]}"; do
        if [ ! -f "./ssl/$file" ]; then
            missing_files+=("$file")
        fi
    done
    
    if [ ${#missing_files[@]} -gt 0 ]; then
        log_warning "ç¼ºå°‘ SSL è¯ä¹¦æ–‡ä»¶: ${missing_files[*]}"
        
        if [ "$FORCE_DEPLOY" != true ]; then
            echo "é€‰æ‹©å¤„ç†æ–¹å¼ï¼š"
            echo "1. è‡ªåŠ¨ç”Ÿæˆè‡ªç­¾åè¯ä¹¦ï¼ˆç”¨äºæµ‹è¯•ï¼‰"
            echo "2. æ‰‹åŠ¨é…ç½®è¯ä¹¦åç»§ç»­"
            echo "3. å–æ¶ˆéƒ¨ç½²"
            read -p "è¯·é€‰æ‹© (1/2/3): " choice
            
            case $choice in
                1)
                    generate_self_signed_cert
                    ;;
                2)
                    log_info "è¯·æ‰‹åŠ¨é…ç½®è¯ä¹¦æ–‡ä»¶åé‡æ–°è¿è¡Œéƒ¨ç½²"
                    exit 0
                    ;;
                3)
                    log_info "éƒ¨ç½²å·²å–æ¶ˆ"
                    exit 0
                    ;;
                *)
                    log_error "æ— æ•ˆé€‰æ‹©"
                    exit 1
                    ;;
            esac
        else
            generate_self_signed_cert
        fi
    else
        log_success "SSL è¯ä¹¦æ£€æŸ¥é€šè¿‡"
    fi
}

# ç”Ÿæˆè‡ªç­¾åè¯ä¹¦
generate_self_signed_cert() {
    log_info "ç”Ÿæˆè‡ªç­¾åè¯ä¹¦..."
    
    openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
        -keyout ssl/cf_key.pem \
        -out ssl/cf_cert.pem \
        -subj "/C=CN/ST=Beijing/L=Beijing/O=My Project/CN=localhost" \
        2>/dev/null
    
    if [ $? -eq 0 ]; then
        log_success "è‡ªç­¾åè¯ä¹¦ç”Ÿæˆå®Œæˆ"
    else
        log_error "è¯ä¹¦ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ openssl æ˜¯å¦å®‰è£…"
        exit 1
    fi
}

# æ›´æ–°ä»£ç 
update_code() {
    local branch="${1:-$DEFAULT_BRANCH}"
    
    log_info "æ›´æ–°ä»£ç åˆ°æœ€æ–°ç‰ˆæœ¬..."
    
    # æ£€æŸ¥æ˜¯å¦åœ¨ Git ä»“åº“ä¸­
    if [ ! -d ".git" ]; then
        log_error "å½“å‰ç›®å½•ä¸æ˜¯ Git ä»“åº“"
        exit 1
    fi
    
    # ä¿å­˜å½“å‰çŠ¶æ€
    local current_branch=$(git branch --show-current)
    local has_changes=$(git status --porcelain)
    
    if [ -n "$has_changes" ]; then
        log_warning "æ£€æµ‹åˆ°æœªæäº¤çš„æ›´æ”¹"
        
        if [ "$FORCE_DEPLOY" != true ]; then
            read -p "æ˜¯å¦ç»§ç»­éƒ¨ç½²ï¼Ÿè¿™å°†æš‚å­˜æœ¬åœ°æ›´æ”¹ (y/N): " confirm
            if [[ ! $confirm =~ ^[Yy]$ ]]; then
                log_info "éƒ¨ç½²å·²å–æ¶ˆ"
                exit 0
            fi
        fi
        
        git stash push -m "Auto-stash before deploy $(date)"
    fi
    
    # åˆ‡æ¢åˆ°ç›®æ ‡åˆ†æ”¯å¹¶æ‹‰å–æœ€æ–°ä»£ç 
    if [ "$current_branch" != "$branch" ]; then
        git checkout "$branch"
    fi
    
    git fetch origin
    git reset --hard "origin/$branch"
    
    log_success "ä»£ç æ›´æ–°å®Œæˆ"
    
    # æ˜¾ç¤ºæœ€æ–°æäº¤ä¿¡æ¯
    echo ""
    log_info "å½“å‰ç‰ˆæœ¬ä¿¡æ¯:"
    git log --oneline -3
    echo ""
}

# æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
check_deployment_status() {
    log_info "æ£€æŸ¥å½“å‰éƒ¨ç½²çŠ¶æ€..."
    
    if [ ! -f ".env.production.local" ]; then
        echo "ğŸ”´ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶ .env.production.local"
        return 1
    fi
    
    local running_containers=$(docker compose -f docker-compose.prod.yml --env-file .env.production.local ps -q 2>/dev/null | wc -l)
    
    if [ "$running_containers" -gt 0 ]; then
        echo "ğŸŸ¢ æ£€æµ‹åˆ°è¿è¡Œä¸­çš„æœåŠ¡ ($running_containers ä¸ªå®¹å™¨)"
        docker compose -f docker-compose.prod.yml --env-file .env.production.local ps
        return 0
    else
        echo "ğŸ”´ æœªæ£€æµ‹åˆ°è¿è¡Œä¸­çš„æœåŠ¡"
        return 1
    fi
}

# é¦–æ¬¡éƒ¨ç½²
first_deploy() {
    log_info "æ‰§è¡Œé¦–æ¬¡éƒ¨ç½²..."
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡æ–‡ä»¶
    setup_environment_config
    
    # æ„å»ºå¹¶å¯åŠ¨æœåŠ¡
    log_info "æ„å»º Docker é•œåƒ..."
    docker compose -f docker-compose.prod.yml --env-file .env.production.local build --no-cache
    
    log_info "å¯åŠ¨æ‰€æœ‰æœåŠ¡..."
    docker compose -f docker-compose.prod.yml --env-file .env.production.local up -d
    
    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    wait_for_services
    
    # è¿è¡Œæ•°æ®åº“è¿ç§»
    run_database_migration
    
    log_success "é¦–æ¬¡éƒ¨ç½²å®Œæˆ"
}

# æ»šåŠ¨æ›´æ–°
rolling_update() {
    log_info "æ‰§è¡Œæ»šåŠ¨æ›´æ–°..."
    
    # æ„å»ºæ–°é•œåƒ
    log_info "æ„å»ºæ–°ç‰ˆæœ¬é•œåƒ..."
    docker compose -f docker-compose.prod.yml --env-file .env.production.local build --no-cache
    
    # æ»šåŠ¨æ›´æ–°æœåŠ¡
    local services=("backend" "web" "admin" "nginx")
    
    for service in "${services[@]}"; do
        log_info "æ›´æ–°æœåŠ¡: $service"
        
        if docker compose -f docker-compose.prod.yml --env-file .env.production.local ps --services | grep -q "^$service$"; then
            docker compose -f docker-compose.prod.yml --env-file .env.production.local up -d --no-deps --force-recreate "$service"
            
            # ç­‰å¾…æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡
            wait_for_service_health "$service"
            
            sleep 3
        else
            log_warning "è·³è¿‡ä¸å­˜åœ¨çš„æœåŠ¡: $service"
        fi
    done
    
    log_success "æ»šåŠ¨æ›´æ–°å®Œæˆ"
}

# è®¾ç½®ç¯å¢ƒé…ç½®
setup_environment_config() {
    if [ ! -f ".env.production.local" ]; then
        if [ -f ".env.production" ]; then
            log_info "åˆ›å»ºç”Ÿäº§ç¯å¢ƒé…ç½®..."
            cp .env.production .env.production.local
            log_warning "è¯·ç¼–è¾‘ .env.production.local æ–‡ä»¶é…ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡"
            
            if [ "$FORCE_DEPLOY" != true ]; then
                read -p "æ˜¯å¦å·²é…ç½®ç¯å¢ƒå˜é‡ï¼Ÿ(y/N): " confirm
                if [[ ! $confirm =~ ^[Yy]$ ]]; then
                    log_info "è¯·å…ˆé…ç½®ç¯å¢ƒå˜é‡åå†è¿è¡Œéƒ¨ç½²"
                    exit 0
                fi
            fi
        else
            log_error "æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡é…ç½®æ–‡ä»¶ .env.production"
            exit 1
        fi
    fi
    
    # éªŒè¯å…³é”®ç¯å¢ƒå˜é‡
    source .env.production.local
    
    local required_vars=("JWT_SECRET" "POSTGRES_PASSWORD")
    local missing_vars=()
    
    for var in "${required_vars[@]}"; do
        if [ -z "${!var}" ] || [ "${!var}" = "your-secure-${var,,}" ]; then
            missing_vars+=("$var")
        fi
    done
    
    if [ ${#missing_vars[@]} -gt 0 ]; then
        log_error "è¯·åœ¨ .env.production.local ä¸­è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡: ${missing_vars[*]}"
        exit 1
    fi
}

# ç­‰å¾…æœåŠ¡å¯åŠ¨
wait_for_services() {
    log_info "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
    
    local max_attempts=60
    local attempt=0
    
    while [ $attempt -lt $max_attempts ]; do
        local healthy_services=$(docker compose -f docker-compose.prod.yml --env-file .env.production.local ps --format json | jq -r 'select(.Health == "healthy") | .Name' | wc -l)
        local total_services=$(docker compose -f docker-compose.prod.yml --env-file .env.production.local ps --format json | jq -r '.Name' | wc -l)
        
        if [ "$healthy_services" -eq "$total_services" ] && [ "$total_services" -gt 0 ]; then
            log_success "æ‰€æœ‰æœåŠ¡å¯åŠ¨å®Œæˆ"
            return 0
        fi
        
        sleep 5
        attempt=$((attempt + 1))
        echo -n "."
    done
    
    log_warning "æœåŠ¡å¯åŠ¨è¶…æ—¶ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€"
    return 1
}

# ç­‰å¾…å•ä¸ªæœåŠ¡å¥åº·æ£€æŸ¥
wait_for_service_health() {
    local service="$1"
    local max_attempts=30
    local attempt=0
    
    while [ $attempt -lt $max_attempts ]; do
        local health=$(docker compose -f docker-compose.prod.yml --env-file .env.production.local ps --format json | jq -r "select(.Service == \"$service\") | .Health")
        
        if [ "$health" = "healthy" ]; then
            log_success "$service æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡"
            return 0
        fi
        
        sleep 5
        attempt=$((attempt + 1))
        echo -n "."
    done
    
    log_warning "$service æœåŠ¡å¥åº·æ£€æŸ¥è¶…æ—¶"
    return 1
}

# è¿è¡Œæ•°æ®åº“è¿ç§»
run_database_migration() {
    log_info "è¿è¡Œæ•°æ®åº“è¿ç§»..."
    
    # ç­‰å¾…åç«¯æœåŠ¡å®Œå…¨å¯åŠ¨
    sleep 30
    
    # æ‰§è¡Œæ•°æ®åº“è¿ç§»
    if docker exec project-backend sh -c "cd apps/backend && ./node_modules/.bin/prisma migrate deploy" > /dev/null 2>&1; then
        log_success "æ•°æ®åº“è¿ç§»å®Œæˆ"
    else
        log_warning "æ•°æ®åº“è¿ç§»å¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥åç«¯æ—¥å¿—"
    fi
}

# éªŒè¯éƒ¨ç½²
verify_deployment() {
    log_info "éªŒè¯éƒ¨ç½²ç»“æœ..."
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    echo ""
    log_info "æœåŠ¡çŠ¶æ€:"
    docker compose -f docker-compose.prod.yml --env-file .env.production.local ps
    
    # æµ‹è¯•æœåŠ¡è¿é€šæ€§
    local services=(
        "http://localhost:4000/health:åç«¯API"
        "http://localhost:80/health:Nginxå¥åº·æ£€æŸ¥"
    )
    
    echo ""
    log_info "è¿é€šæ€§æµ‹è¯•:"
    
    local failed_services=()
    
    for service_info in "${services[@]}"; do
        local url=$(echo "$service_info" | cut -d: -f1-2)
        local name=$(echo "$service_info" | cut -d: -f3)
        
        if curl -s --max-time 10 "$url" > /dev/null; then
            echo "  âœ… $name"
        else
            echo "  âŒ $name"
            failed_services+=("$name")
        fi
    done
    
    if [ ${#failed_services[@]} -eq 0 ]; then
        log_success "æ‰€æœ‰æœåŠ¡éªŒè¯é€šè¿‡"
        return 0
    else
        log_warning "ä»¥ä¸‹æœåŠ¡éªŒè¯å¤±è´¥: ${failed_services[*]}"
        return 1
    fi
}

# åˆ›å»ºæ•°æ®å¤‡ä»½
create_backup() {
    log_info "åˆ›å»ºæ•°æ®å¤‡ä»½..."
    
    local backup_dir="/tmp/backups"
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_file="backup_${timestamp}.sql"
    
    mkdir -p "$backup_dir"
    
    # å¤‡ä»½æ•°æ®åº“
    if docker exec project-postgres pg_dump -U postgres my_project > "$backup_dir/$backup_file"; then
        log_success "æ•°æ®å¤‡ä»½å®Œæˆ: $backup_dir/$backup_file"
    else
        log_error "æ•°æ®å¤‡ä»½å¤±è´¥"
        return 1
    fi
    
    # å‹ç¼©å¤‡ä»½æ–‡ä»¶
    gzip "$backup_dir/$backup_file"
    
    # æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™æœ€è¿‘ 7 ä¸ªï¼‰
    (cd "$backup_dir" && ls -t backup_*.sql.gz | tail -n +8 | xargs -r rm)
    
    log_success "å¤‡ä»½åˆ›å»ºå®Œæˆ"
}

# æ˜¾ç¤ºæœåŠ¡æ—¥å¿—
show_logs() {
    log_info "æ˜¾ç¤ºæœåŠ¡æ—¥å¿—..."
    
    if [ ! -f ".env.production.local" ]; then
        log_error "æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡æ–‡ä»¶"
        exit 1
    fi
    
    docker compose -f docker-compose.prod.yml --env-file .env.production.local logs --tail=50 -f
}

# æ˜¾ç¤ºéƒ¨ç½²å®Œæˆä¿¡æ¯
show_deployment_info() {
    echo ""
    echo "ğŸ‰ éƒ¨ç½²å®Œæˆï¼"
    echo "=============="
    echo ""
    echo "ğŸ“± æœåŠ¡åœ°å€:"
    echo "  ğŸŒ å‰ç«¯: https://hw.knzn.net"
    echo "  ğŸ”§ ç®¡ç†ç«¯: https://admin.knzn.net"
    echo "  ğŸš€ API: https://hw.knzn.net/api"
    echo ""
    echo "ğŸ”§ ç®¡ç†å‘½ä»¤:"
    echo "  æŸ¥çœ‹çŠ¶æ€: $0 --check"
    echo "  æŸ¥çœ‹æ—¥å¿—: $0 --logs"
    echo "  åˆ›å»ºå¤‡ä»½: $0 --backup"
    echo ""
    echo "ğŸ“Š éƒ¨ç½²ä¿¡æ¯:"
    echo "  éƒ¨ç½²æ—¶é—´: $(date)"
    echo "  Git åˆ†æ”¯: $(git branch --show-current)"
    echo "  Git æäº¤: $(git log --oneline -1)"
    echo ""
}

# ä¸»å‡½æ•°
main() {
    local branch="$DEFAULT_BRANCH"
    local force_first_deploy=false
    local force_update_only=false
    local check_only=false
    local show_logs_flag=false
    local backup_flag=false
    local service_name=""
    FORCE_DEPLOY=false
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help)
                show_help
                exit 0
                ;;
            -b|--branch)
                branch="$2"
                shift 2
                ;;
            -f|--force)
                FORCE_DEPLOY=true
                shift
                ;;
            --first-deploy)
                force_first_deploy=true
                shift
                ;;
            --update-only)
                force_update_only=true
                shift
                ;;
            --check)
                check_only=true
                shift
                ;;
            --logs)
                show_logs_flag=true
                shift
                ;;
            --backup)
                backup_flag=true
                shift
                ;;
            --service)
                service_name="$2"
                shift 2
                ;;
            *)
                log_error "æœªçŸ¥å‚æ•°: $1"
                show_help
                exit 1
                ;;
        esac
    done
    
    echo "ğŸš€ $PROJECT_NAME - Docker å®¹å™¨åŒ–éƒ¨ç½²"
    echo "===================================="
    echo "éƒ¨ç½²åˆ†æ”¯: $branch"
    echo "æ‰§è¡Œæ—¶é—´: $(date)"
    echo ""
    
    # å¤„ç†ç‰¹æ®Šæ“ä½œ
    if [ "$check_only" = true ]; then
        check_deployment_status
        exit 0
    fi
    
    if [ "$show_logs_flag" = true ]; then
        show_logs
        exit 0
    fi
    
    if [ "$backup_flag" = true ]; then
        create_backup
        exit 0
    fi
    
    # å¤„ç†å•æœåŠ¡æ›´æ–°
    if [ -n "$service_name" ]; then
        log_info "æ‰§è¡Œå•æœåŠ¡æ›´æ–°æ¨¡å¼: $service_name"
        check_environment
        update_code "$branch"
        
        # æ„å»ºå¹¶æ›´æ–°å•ä¸ªæœåŠ¡
        docker compose -f docker-compose.prod.yml --env-file .env.production.local build --no-cache "$service_name"
        docker compose -f docker-compose.prod.yml --env-file .env.production.local up -d --no-deps --force-recreate "$service_name"
        
        wait_for_service_health "$service_name"
        exit 0
    fi
    
    # æ‰§è¡Œéƒ¨ç½²æµç¨‹
    check_environment
    check_ssl_certificates
    update_code "$branch"
    
    # æ™ºèƒ½åˆ¤æ–­éƒ¨ç½²æ¨¡å¼
    local is_deployed=false
    if check_deployment_status > /dev/null 2>&1; then
        is_deployed=true
    fi
    
    if [ "$force_first_deploy" = true ] || ([ "$force_update_only" = false ] && [ "$is_deployed" = false ]); then
        first_deploy
    elif [ "$force_update_only" = true ] || [ "$is_deployed" = true ]; then
        rolling_update
    fi
    
    # éªŒè¯éƒ¨ç½²ç»“æœ
    echo ""
    if verify_deployment; then
        show_deployment_info
    else
        log_warning "éƒ¨ç½²éªŒè¯å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€"
        log_info "æŸ¥çœ‹æ—¥å¿—: $0 --logs"
        exit 1
    fi
}

main "$@"
```

## ğŸ“Š ç›‘æ§å’Œç»´æŠ¤

### 1. å¥åº·æ£€æŸ¥é…ç½®

```yaml
# åœ¨ docker-compose.prod.yml ä¸­çš„å¥åº·æ£€æŸ¥ç¤ºä¾‹
healthcheck:
  test: ['CMD', 'curl', '-f', 'http://localhost:4000/health']
  interval: 30s      # æ£€æŸ¥é—´éš”
  timeout: 10s       # è¶…æ—¶æ—¶é—´
  retries: 3         # é‡è¯•æ¬¡æ•°
  start_period: 60s  # å¯åŠ¨å®½é™æœŸ
```

### 2. æ—¥å¿—ç®¡ç†

```bash
# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—
docker compose -f docker-compose.prod.yml logs

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
docker compose -f docker-compose.prod.yml logs backend

# å®æ—¶è·Ÿè¸ªæ—¥å¿—
docker compose -f docker-compose.prod.yml logs -f

# æŸ¥çœ‹æœ€è¿‘ 100 è¡Œæ—¥å¿—
docker compose -f docker-compose.prod.yml logs --tail=100
```

### 3. æ•°æ®å¤‡ä»½è„šæœ¬

```bash
#!/bin/bash
# scripts/backup.sh

set -e

BACKUP_DIR="/opt/backups"
DATE=$(date +%Y%m%d_%H%M%S)
DB_BACKUP_FILE="db_backup_${DATE}.sql"
FILES_BACKUP_FILE="files_backup_${DATE}.tar.gz"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "$BACKUP_DIR"

# æ•°æ®åº“å¤‡ä»½
echo "å¼€å§‹æ•°æ®åº“å¤‡ä»½..."
docker exec project-postgres pg_dump -U postgres my_project > "$BACKUP_DIR/$DB_BACKUP_FILE"

# å‹ç¼©æ•°æ®åº“å¤‡ä»½
gzip "$BACKUP_DIR/$DB_BACKUP_FILE"

# æ–‡ä»¶å¤‡ä»½ï¼ˆå¦‚æœæœ‰ä¸Šä¼ æ–‡ä»¶ï¼‰
if [ -d "./uploads" ]; then
    echo "å¼€å§‹æ–‡ä»¶å¤‡ä»½..."
    tar -czf "$BACKUP_DIR/$FILES_BACKUP_FILE" uploads/
fi

# æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™ 7 å¤©ï¼‰
find "$BACKUP_DIR" -name "*.sql.gz" -mtime +7 -delete
find "$BACKUP_DIR" -name "*.tar.gz" -mtime +7 -delete

echo "å¤‡ä»½å®Œæˆ: $BACKUP_DIR"
```

### 4. æ•°æ®æ¢å¤è„šæœ¬

```bash
#!/bin/bash
# scripts/restore.sh

set -e

if [ $# -ne 1 ]; then
    echo "ç”¨æ³•: $0 <backup_file.sql.gz>"
    exit 1
fi

BACKUP_FILE="$1"

if [ ! -f "$BACKUP_FILE" ]; then
    echo "å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: $BACKUP_FILE"
    exit 1
fi

echo "è­¦å‘Š: è¿™å°†è¦†ç›–å½“å‰æ•°æ®åº“ï¼"
read -p "ç¡®è®¤ç»§ç»­ï¼Ÿ(y/N): " confirm

if [[ ! $confirm =~ ^[Yy]$ ]]; then
    echo "æ“ä½œå·²å–æ¶ˆ"
    exit 0
fi

# åœæ­¢åº”ç”¨æœåŠ¡ï¼ˆä¿ç•™æ•°æ®åº“ï¼‰
docker compose -f docker-compose.prod.yml stop backend web admin

# æ¢å¤æ•°æ®åº“
echo "å¼€å§‹æ¢å¤æ•°æ®åº“..."
gunzip -c "$BACKUP_FILE" | docker exec -i project-postgres psql -U postgres -d my_project

# é‡å¯åº”ç”¨æœåŠ¡
docker compose -f docker-compose.prod.yml start backend web admin

echo "æ•°æ®æ¢å¤å®Œæˆ"
```

## ğŸ”§ æœ€ä½³å®è·µ

### 1. é•œåƒä¼˜åŒ–

- **å¤šé˜¶æ®µæ„å»º**: å‡å°‘æœ€ç»ˆé•œåƒå¤§å°
- **å±‚ç¼“å­˜**: åˆç†å®‰æ’ Dockerfile æŒ‡ä»¤é¡ºåº
- **åŸºç¡€é•œåƒ**: ä½¿ç”¨ Alpine Linux å‡å°‘é•œåƒå¤§å°
- **å®‰å…¨æ‰«æ**: å®šæœŸæ‰«æé•œåƒæ¼æ´

### 2. ç½‘ç»œå®‰å…¨

- **å†…éƒ¨ç½‘ç»œ**: ä½¿ç”¨ Docker å†…éƒ¨ç½‘ç»œéš”ç¦»æœåŠ¡
- **æœ€å°æƒé™**: å®¹å™¨ä»¥é root ç”¨æˆ·è¿è¡Œ
- **ç«¯å£æš´éœ²**: åªæš´éœ²å¿…è¦çš„ç«¯å£
- **SSL/TLS**: å¼ºåˆ¶ä½¿ç”¨ HTTPS

### 3. èµ„æºç®¡ç†

```yaml
# åœ¨ docker-compose.prod.yml ä¸­æ·»åŠ èµ„æºé™åˆ¶
services:
  backend:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
```

### 4. ç¯å¢ƒå˜é‡ç®¡ç†

- **æ•æ„Ÿä¿¡æ¯**: ä½¿ç”¨ Docker Secrets æˆ–å¤–éƒ¨å¯†é’¥ç®¡ç†
- **é…ç½®åˆ†ç¦»**: å¼€å‘å’Œç”Ÿäº§ç¯å¢ƒé…ç½®åˆ†ç¦»
- **é»˜è®¤å€¼**: ä¸ºç¯å¢ƒå˜é‡è®¾ç½®åˆç†é»˜è®¤å€¼

## ğŸ¯ æ€»ç»“

è¿™å¥— Docker å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

1. **ç¯å¢ƒä¸€è‡´æ€§**: å¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ç¯å¢ƒå®Œå…¨ä¸€è‡´
2. **å¿«é€Ÿéƒ¨ç½²**: ä¸€é”®éƒ¨ç½²è„šæœ¬ï¼Œ5åˆ†é’Ÿå®Œæˆéƒ¨ç½²
3. **æ˜“äºç»´æŠ¤**: å®¹å™¨åŒ–ç®¡ç†ï¼ŒæœåŠ¡éš”ç¦»
4. **å¯æ‰©å±•æ€§**: æ”¯æŒæ°´å¹³æ‰©å±•å’Œè´Ÿè½½å‡è¡¡
5. **å®‰å…¨å¯é **: SSL åŠ å¯†ã€å¥åº·æ£€æŸ¥ã€è‡ªåŠ¨é‡å¯
6. **è¿ç»´å‹å¥½**: å®Œæ•´çš„æ—¥å¿—ã€ç›‘æ§ã€å¤‡ä»½æ–¹æ¡ˆ

é€‚ç”¨äºéœ€è¦å¿«é€Ÿéƒ¨ç½²ã€ç¨³å®šè¿è¡Œçš„ç”Ÿäº§ç¯å¢ƒé¡¹ç›®ã€‚